{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7b6e3d3403d439b8f29a68a20c06f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78924bf767db4008bb6225ecd3d658c9",
              "IPY_MODEL_6b75b2a88c2d4b7388ed74343e6f8bef",
              "IPY_MODEL_575457c908f5425385410b582c005f8a"
            ],
            "layout": "IPY_MODEL_ac4b4f386f034b62bc7db50f010f276b"
          }
        },
        "78924bf767db4008bb6225ecd3d658c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4501dc24bde4c8a8596fb396199dcf4",
            "placeholder": "​",
            "style": "IPY_MODEL_5abe62f6e77047ee97b8b7ec9079bf6a",
            "value": "Ensemble predicting: 100%"
          }
        },
        "6b75b2a88c2d4b7388ed74343e6f8bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd957ed7fe87447599be4376d3d9dd3a",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_665fa26d4a3e45a0aee668d6158b066f",
            "value": 20
          }
        },
        "575457c908f5425385410b582c005f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9bced5e1184fcfbe72764fe72f3f8e",
            "placeholder": "​",
            "style": "IPY_MODEL_cd6877f86ffe41ec9e7a29fce142d615",
            "value": " 20/20 [00:14&lt;00:00,  2.04it/s]"
          }
        },
        "ac4b4f386f034b62bc7db50f010f276b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4501dc24bde4c8a8596fb396199dcf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abe62f6e77047ee97b8b7ec9079bf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd957ed7fe87447599be4376d3d9dd3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665fa26d4a3e45a0aee668d6158b066f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9bced5e1184fcfbe72764fe72f3f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6877f86ffe41ec9e7a29fce142d615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28cd635acc04efcace6ce35cd6deff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2a25c6d29f54ffc89c8e17b6e413628",
              "IPY_MODEL_9dcca94f6b954d82a61e162193719992",
              "IPY_MODEL_528cce75469a4a3093886e686825b300"
            ],
            "layout": "IPY_MODEL_e8cd55d8903748408f9ffa069955647f"
          }
        },
        "e2a25c6d29f54ffc89c8e17b6e413628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef6706e26c54b368057f2aab9734869",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ad06a0d88f48488460cf521ebbc2f3",
            "value": "TTA variants: 100%"
          }
        },
        "9dcca94f6b954d82a61e162193719992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_200976f0ca354f0aa99cd9bf0cb3293e",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a30f1f0df664463908cdcea4e877e3b",
            "value": 4
          }
        },
        "528cce75469a4a3093886e686825b300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01b235ad4cf14d79a336b711b8cd2704",
            "placeholder": "​",
            "style": "IPY_MODEL_01c160d929a6471b939f9b291e220424",
            "value": " 4/4 [00:38&lt;00:00,  9.75s/it]"
          }
        },
        "e8cd55d8903748408f9ffa069955647f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef6706e26c54b368057f2aab9734869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ad06a0d88f48488460cf521ebbc2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "200976f0ca354f0aa99cd9bf0cb3293e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a30f1f0df664463908cdcea4e877e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01b235ad4cf14d79a336b711b8cd2704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c160d929a6471b939f9b291e220424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9JHu6taluWpu",
        "outputId": "39e477e0-9a1a-480c-8a06-513c7a930cba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nDAY 5: MODEL OPTIMIZATION & ACCURACY IMPROVEMENT\\n================================================================================\\nFocus: Reduce overfitting, improve test accuracy, ensemble methods\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "DAY 5: MODEL OPTIMIZATION & ACCURACY IMPROVEMENT\n",
        "================================================================================\n",
        "Focus: Reduce overfitting, improve test accuracy, ensemble methods\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create directory structure\n",
        "os.makedirs('notebooks/outputs', exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"UPLOAD DAY 4 OUTPUT FILES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# List of required files\n",
        "required_files = [\n",
        "    'cv_statistics.json',\n",
        "    'test_set_results.json',\n",
        "    'all_folds_results.json',\n",
        "    'class_weights.json',\n",
        "    'dataset_info.json'\n",
        "]\n",
        "\n",
        "uploaded_count = 0\n",
        "\n",
        "print(\"Please upload the following 5 files one by one:\")\n",
        "print(\"Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/notebooks/outputs/\")\n",
        "print()\n",
        "\n",
        "for i, filename in enumerate(required_files, 1):\n",
        "    print(f\"({i}/5) Please upload: {filename}\")\n",
        "    print(\"Click 'Choose Files' then 'Upload'\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        # Move the uploaded file to correct location\n",
        "        for uploaded_filename in uploaded.keys():\n",
        "            os.rename(uploaded_filename, f'notebooks/outputs/{filename}')\n",
        "            print(f\"Successfully uploaded: {filename}\")\n",
        "            uploaded_count += 1\n",
        "    else:\n",
        "        print(f\"Warning: {filename} was not uploaded\")\n",
        "\n",
        "    print()\n",
        "\n",
        "print(\"=\"*80)\n",
        "if uploaded_count == 5:\n",
        "    print(\"SUCCESS: All 5 files uploaded successfully!\")\n",
        "    print(\"You can now proceed with Day 5 analysis.\")\n",
        "else:\n",
        "    print(f\"PARTIAL: {uploaded_count}/5 files uploaded.\")\n",
        "    print(\"Some analysis features may not work properly.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "osmr741gi30i",
        "outputId": "25468f87-0918-4526-ba29-c218abf7b918"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "UPLOAD DAY 4 OUTPUT FILES\n",
            "================================================================================\n",
            "Please upload the following 5 files one by one:\n",
            "Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/notebooks/outputs/\n",
            "\n",
            "(1/5) Please upload: cv_statistics.json\n",
            "Click 'Choose Files' then 'Upload'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-479bbf0a-9f7f-46bf-aa52-a5f1f3fcb23a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-479bbf0a-9f7f-46bf-aa52-a5f1f3fcb23a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cv_statistics.json to cv_statistics.json\n",
            "Successfully uploaded: cv_statistics.json\n",
            "\n",
            "(2/5) Please upload: test_set_results.json\n",
            "Click 'Choose Files' then 'Upload'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3040064-5c77-4ac8-ba47-fb4d925f07a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3040064-5c77-4ac8-ba47-fb4d925f07a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_set_results.json to test_set_results.json\n",
            "Successfully uploaded: test_set_results.json\n",
            "\n",
            "(3/5) Please upload: all_folds_results.json\n",
            "Click 'Choose Files' then 'Upload'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b23fc04-e5cb-48a8-811c-f3af147619fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b23fc04-e5cb-48a8-811c-f3af147619fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving all_folds_results.json to all_folds_results.json\n",
            "Successfully uploaded: all_folds_results.json\n",
            "\n",
            "(4/5) Please upload: class_weights.json\n",
            "Click 'Choose Files' then 'Upload'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68c5e79d-5fd1-4a62-ab7b-d472824f128c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-68c5e79d-5fd1-4a62-ab7b-d472824f128c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving class_weights.json to class_weights.json\n",
            "Successfully uploaded: class_weights.json\n",
            "\n",
            "(5/5) Please upload: dataset_info.json\n",
            "Click 'Choose Files' then 'Upload'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c020c12-6495-4b88-b70a-2511b2165318\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c020c12-6495-4b88-b70a-2511b2165318\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_info.json to dataset_info.json\n",
            "Successfully uploaded: dataset_info.json\n",
            "\n",
            "================================================================================\n",
            "SUCCESS: All 5 files uploaded successfully!\n",
            "You can now proceed with Day 5 analysis.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 1: SETUP & DAY 4 ANALYSIS\n",
        "#================================================================================\n",
        "\"\"\"\n",
        "What this does: Load and analyze Day 4 results, identify issues\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                              f1_score, confusion_matrix, classification_report)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DAY 5: MODEL OPTIMIZATION & ACCURACY IMPROVEMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nDevice: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Create directories\n",
        "Path('outputs').mkdir(exist_ok=True)\n",
        "Path('visualizations').mkdir(exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYZING DAY 4 RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def load_day4_results():\n",
        "    \"\"\"Load Day 4 results from multiple possible locations\"\"\"\n",
        "    file_locations = [\n",
        "        'notebooks/outputs/',  # Colab uploaded location\n",
        "        'outputs/',            # Original expected location\n",
        "        '/content/notebooks/outputs/',  # Absolute Colab path\n",
        "    ]\n",
        "\n",
        "    files_to_load = {\n",
        "        'cv_statistics.json': None,\n",
        "        'test_set_results.json': None,\n",
        "        'all_folds_results.json': None\n",
        "    }\n",
        "\n",
        "    # Try to find files in different locations\n",
        "    for location in file_locations:\n",
        "        for filename in files_to_load.keys():\n",
        "            file_path = os.path.join(location, filename)\n",
        "            if os.path.exists(file_path) and files_to_load[filename] is None:\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        files_to_load[filename] = json.load(f)\n",
        "                    print(f\"✓ Loaded {filename} from {location}\")\n",
        "                except Exception as e:\n",
        "                    print(f\" Could not load {filename} from {location}: {e}\")\n",
        "\n",
        "    # Check if all files were found\n",
        "    missing_files = [f for f, data in files_to_load.items() if data is None]\n",
        "    if missing_files:\n",
        "        raise FileNotFoundError(f\"Missing files: {missing_files}\")\n",
        "\n",
        "    return files_to_load['cv_statistics.json'], files_to_load['test_set_results.json'], files_to_load['all_folds_results.json']['all_results']\n",
        "\n",
        "# Load Day 4 results\n",
        "try:\n",
        "    cv_stats, test_results, all_folds = load_day4_results()\n",
        "    print(\"\\nSuccessfully loaded all Day 4 results!\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nERROR: {e}\")\n",
        "    print(\"\\nPlease ensure you've uploaded all 5 Day 4 output files.\")\n",
        "    print(\"Expected files: cv_statistics.json, test_set_results.json, all_folds_results.json\")\n",
        "    raise\n",
        "\n",
        "# Print Day 4 summary\n",
        "print(f\"\\n[DAY 4 PERFORMANCE SUMMARY]\")\n",
        "print(f\"Cross-Validation: {cv_stats['mean_accuracy']:.4f} +/- {cv_stats['std_accuracy']:.4f}\")\n",
        "print(f\"Test Set:         {test_results['test_accuracy']:.4f}\")\n",
        "print(f\"Generalization:   {test_results['test_accuracy'] - cv_stats['mean_accuracy']:+.4f}\")\n",
        "\n",
        "# Identify specific issues\n",
        "gap = cv_stats['mean_accuracy'] - test_results['test_accuracy']\n",
        "print(f\"\\n[ISSUES IDENTIFIED]\")\n",
        "if gap > 0.05:\n",
        "    print(f\"  1. OVERFITTING: {gap:.4f} ({gap:.2%}) gap between CV and test\")\n",
        "if test_results['test_accuracy'] < 0.90:\n",
        "    print(f\"  2. SUBOPTIMAL PERFORMANCE: Test accuracy {test_results['test_accuracy']:.2%} < 90% target\")\n",
        "if cv_stats['std_accuracy'] > 0.01:\n",
        "    print(f\"  3. HIGH VARIANCE: Std across folds: {cv_stats['std_accuracy']:.4f}\")\n",
        "\n",
        "# Per-fold analysis\n",
        "print(f\"\\n[PER-FOLD BREAKDOWN]\")\n",
        "for fold_data in all_folds:\n",
        "    fold = fold_data['fold']\n",
        "    acc = fold_data['accuracy']\n",
        "    marker = \" ← BEST\" if fold == cv_stats['best_fold'] else \"\"\n",
        "    print(f\"  Fold {fold}: {acc:.4f}{marker}\")\n",
        "\n",
        "print(f\"\\n[DAY 5 OPTIMIZATION STRATEGY]\")\n",
        "print(\"  1. Ensemble Learning: Combine all 5 fold models (+2-4% expected)\")\n",
        "print(\"  2. Test Time Augmentation: Multiple augmented predictions (+1-3% expected)\")\n",
        "print(\"  3. Combined Approach: Ensemble + TTA (Target: 88-91% accuracy)\")\n",
        "print(\"  4. Address class imbalance and overfitting\")\n",
        "\n",
        "print(\"\\n Analysis complete! Ready for optimization.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7QfkdaFuqAS",
        "outputId": "39f0ccda-c4d9-4fb0-8fc9-2ab2fd64d6b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DAY 5: MODEL OPTIMIZATION & ACCURACY IMPROVEMENT\n",
            "================================================================================\n",
            "\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n",
            "\n",
            "================================================================================\n",
            "ANALYZING DAY 4 RESULTS\n",
            "================================================================================\n",
            "✓ Loaded cv_statistics.json from notebooks/outputs/\n",
            "✓ Loaded test_set_results.json from notebooks/outputs/\n",
            "✓ Loaded all_folds_results.json from notebooks/outputs/\n",
            "\n",
            "Successfully loaded all Day 4 results!\n",
            "\n",
            "[DAY 4 PERFORMANCE SUMMARY]\n",
            "Cross-Validation: 0.9373 +/- 0.0060\n",
            "Test Set:         0.8526\n",
            "Generalization:   -0.0847\n",
            "\n",
            "[ISSUES IDENTIFIED]\n",
            "  1. OVERFITTING: 0.0847 (8.47%) gap between CV and test\n",
            "  2. SUBOPTIMAL PERFORMANCE: Test accuracy 85.26% < 90% target\n",
            "\n",
            "[PER-FOLD BREAKDOWN]\n",
            "  Fold 1: 0.9368\n",
            "  Fold 2: 0.9425 ← BEST\n",
            "  Fold 3: 0.9262\n",
            "  Fold 4: 0.9386\n",
            "  Fold 5: 0.9425\n",
            "\n",
            "[DAY 5 OPTIMIZATION STRATEGY]\n",
            "  1. Ensemble Learning: Combine all 5 fold models (+2-4% expected)\n",
            "  2. Test Time Augmentation: Multiple augmented predictions (+1-3% expected)\n",
            "  3. Combined Approach: Ensemble + TTA (Target: 88-91% accuracy)\n",
            "  4. Address class imbalance and overfitting\n",
            "\n",
            " Analysis complete! Ready for optimization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 2: ENSEMBLE PREDICTION (QUICK WIN #1)\n",
        "#================================================================================\n",
        "\"\"\"\n",
        "What this does: Use all 5 models together for better predictions\n",
        "Expected improvement: +2-4% accuracy\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ENSEMBLE PREDICTION (ALL 5 MODELS)\")\n",
        "print(\"=\"*80)\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "\n",
        "# Load dataset info\n",
        "with open('notebooks/outputs/dataset_info.json', 'r') as f:\n",
        "    dataset_info = json.load(f)\n",
        "\n",
        "class_names = dataset_info['class_names']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# ===  SMART DATASET PATH DETECTION ===\n",
        "print(f\"Original test directory: {dataset_info['test_dir']}\")\n",
        "\n",
        "def find_test_dataset():\n",
        "    \"\"\"Find test dataset in multiple possible locations\"\"\"\n",
        "    possible_paths = [\n",
        "        dataset_info['test_dir'],  # Original path from Day 4\n",
        "        '/content/data/chest_xray/test',  # Common Colab path\n",
        "        '../data/chest_xray/test',  # Relative path\n",
        "        'data/chest_xray/test',  # Local data folder\n",
        "    ]\n",
        "\n",
        "    for path in possible_paths:\n",
        "        test_path = Path(path)\n",
        "        if test_path.exists():\n",
        "            print(f\"✓ Found test dataset at: {path}\")\n",
        "            return test_path\n",
        "\n",
        "    # If no dataset found, download it\n",
        "    print(\"Dataset not found. Downloading from Kaggle...\")\n",
        "    return download_dataset()\n",
        "\n",
        "def download_dataset():\n",
        "    \"\"\"Download dataset from Kaggle\"\"\"\n",
        "    !pip install -q kaggle\n",
        "\n",
        "    # Create directories\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "    from google.colab import files\n",
        "    print(\"Please upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if 'kaggle.json' in uploaded:\n",
        "        !mv kaggle.json /root/.kaggle/\n",
        "        !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "        # Download dataset\n",
        "        !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content/data/ --force\n",
        "\n",
        "        # Extract\n",
        "        import zipfile\n",
        "        with zipfile.ZipFile('/content/data/chest-xray-pneumonia.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/data/')\n",
        "\n",
        "        return Path('/content/data/chest_xray/test')\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Please upload kaggle.json or the dataset manually\")\n",
        "\n",
        "# Find test dataset\n",
        "test_dir = find_test_dataset()\n",
        "\n",
        "# Load test dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = ImageFolder(root=str(test_dir), transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\nTest set: {len(test_dataset)} images\")\n",
        "\n",
        "# Build model function (from Day 4)\n",
        "def build_model(num_classes=2, dropout_rate=0.5):\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model.to(device)\n",
        "\n",
        "# ===  SMART MODEL PATH DETECTION WITH UPLOAD ===\n",
        "print(\"\\nLoading all 5 fold models...\")\n",
        "models_list = []\n",
        "\n",
        "def find_model_path(fold):\n",
        "    \"\"\"Find model file or upload if not found\"\"\"\n",
        "    possible_paths = [\n",
        "        f'notebooks/models/resnet50_fold_{fold}_best.pth',\n",
        "        f'models/resnet50_fold_{fold}_best.pth',\n",
        "        f'/content/notebooks/models/resnet50_fold_{fold}_best.pth',\n",
        "        f'/content/models/resnet50_fold_{fold}_best.pth',\n",
        "    ]\n",
        "\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"  Found Fold {fold} at: {path}\")\n",
        "            return path\n",
        "\n",
        "    # If model not found, upload it\n",
        "    print(f\"\\nModel for fold {fold} not found in Colab.\")\n",
        "    print(f\"Please upload: resnet50_fold_{fold}_best.pth\")\n",
        "    print(\"Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/models/\")\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if f'fold_{fold}' in filename or filename.endswith('.pth'):\n",
        "            # Move to standard location\n",
        "            os.makedirs('notebooks/models', exist_ok=True)\n",
        "            new_path = f'notebooks/models/resnet50_fold_{fold}_best.pth'\n",
        "            os.rename(filename, new_path)\n",
        "            print(f\"Uploaded and moved to: {new_path}\")\n",
        "            return new_path\n",
        "\n",
        "    raise FileNotFoundError(f\"Please upload model for fold {fold}\")\n",
        "\n",
        "for fold in range(1, 6):\n",
        "    checkpoint_path = find_model_path(fold)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    model = build_model(num_classes=num_classes, dropout_rate=0.5)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    models_list.append(model)\n",
        "    print(f\"  Loaded Fold {fold} model\")\n",
        "\n",
        "# Ensemble prediction function\n",
        "def ensemble_predict(models, dataloader):\n",
        "    \"\"\"Average predictions from multiple models\"\"\"\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc='Ensemble predicting'):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Get predictions from all models\n",
        "            batch_probs = []\n",
        "            for model in models:\n",
        "                outputs = model(images)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                batch_probs.append(probs.cpu().numpy())\n",
        "\n",
        "            # Average probabilities\n",
        "            avg_probs = np.mean(batch_probs, axis=0)\n",
        "            all_probs.extend(avg_probs)\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "    predictions = np.argmax(all_probs, axis=1)\n",
        "\n",
        "    return predictions, all_probs, all_labels\n",
        "\n",
        "# Run ensemble prediction\n",
        "print(\"\\nRunning ensemble prediction on test set...\")\n",
        "ensemble_preds, ensemble_probs, true_labels = ensemble_predict(models_list, test_loader)\n",
        "\n",
        "# Calculate ensemble metrics\n",
        "ensemble_acc = accuracy_score(true_labels, ensemble_preds)\n",
        "ensemble_prec = precision_score(true_labels, ensemble_preds, average='weighted', zero_division=0)\n",
        "ensemble_rec = recall_score(true_labels, ensemble_preds, average='weighted', zero_division=0)\n",
        "ensemble_f1 = f1_score(true_labels, ensemble_preds, average='weighted', zero_division=0)\n",
        "ensemble_cm = confusion_matrix(true_labels, ensemble_preds)\n",
        "\n",
        "print(f\"\\n[ENSEMBLE RESULTS]\")\n",
        "print(f\"Accuracy:  {ensemble_acc:.4f}\")\n",
        "print(f\"Precision: {ensemble_prec:.4f}\")\n",
        "print(f\"Recall:    {ensemble_rec:.4f}\")\n",
        "print(f\"F1-Score:  {ensemble_f1:.4f}\")\n",
        "\n",
        "# Compare to single best model\n",
        "single_best_acc = test_results['test_accuracy']\n",
        "improvement = ensemble_acc - single_best_acc\n",
        "\n",
        "print(f\"\\n[COMPARISON]\")\n",
        "print(f\"Single Best Model: {single_best_acc:.4f}\")\n",
        "print(f\"Ensemble (5 models): {ensemble_acc:.4f}\")\n",
        "print(f\"Improvement: {improvement:+.4f} ({improvement*100:+.2f}%)\")\n",
        "\n",
        "# Per-class performance\n",
        "print(f\"\\n[PER-CLASS PERFORMANCE]\")\n",
        "class_report = classification_report(true_labels, ensemble_preds,\n",
        "                                     target_names=class_names, output_dict=True)\n",
        "for cls in class_names:\n",
        "    metrics = class_report[cls]\n",
        "    print(f\"  {cls:15} Prec: {metrics['precision']:.3f}, \"\n",
        "          f\"Rec: {metrics['recall']:.3f}, F1: {metrics['f1-score']:.3f}\")\n",
        "\n",
        "# Visualize ensemble confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_normalized = ensemble_cm.astype('float') / ensemble_cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "for i in range(len(class_names)):\n",
        "    for j in range(len(class_names)):\n",
        "        plt.text(j+0.5, i+0.7, f'({ensemble_cm[i,j]})',\n",
        "                ha='center', va='center', fontsize=9, color='gray')\n",
        "\n",
        "plt.title(f'Ensemble Confusion Matrix\\nAccuracy: {ensemble_acc:.3f}',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('visualizations/ensemble_confusion_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ===  CORRECT SAVE PATH ===\n",
        "# Save ensemble results\n",
        "ensemble_results = {\n",
        "    'accuracy': float(ensemble_acc),\n",
        "    'precision': float(ensemble_prec),\n",
        "    'recall': float(ensemble_rec),\n",
        "    'f1_score': float(ensemble_f1),\n",
        "    'confusion_matrix': ensemble_cm.tolist(),\n",
        "    'improvement_over_single': float(improvement),\n",
        "    'single_model_accuracy': float(single_best_acc)\n",
        "}\n",
        "\n",
        "with open('notebooks/outputs/ensemble_results.json', 'w') as f:\n",
        "    json.dump(ensemble_results, f, indent=2)\n",
        "\n",
        "print(\"\\nEnsemble results saved to: notebooks/outputs/ensemble_results.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e7b6e3d3403d439b8f29a68a20c06f95",
            "78924bf767db4008bb6225ecd3d658c9",
            "6b75b2a88c2d4b7388ed74343e6f8bef",
            "575457c908f5425385410b582c005f8a",
            "ac4b4f386f034b62bc7db50f010f276b",
            "b4501dc24bde4c8a8596fb396199dcf4",
            "5abe62f6e77047ee97b8b7ec9079bf6a",
            "bd957ed7fe87447599be4376d3d9dd3a",
            "665fa26d4a3e45a0aee668d6158b066f",
            "0d9bced5e1184fcfbe72764fe72f3f8e",
            "cd6877f86ffe41ec9e7a29fce142d615"
          ]
        },
        "id": "cEE3oKVvlPVi",
        "outputId": "38ac16db-db16-4b00-c025-bfd1264e0ad5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ENSEMBLE PREDICTION (ALL 5 MODELS)\n",
            "================================================================================\n",
            "Original test directory: ../data/chest_xray/test\n",
            "✓ Found test dataset at: /content/data/chest_xray/test\n",
            "\n",
            "Test set: 624 images\n",
            "\n",
            "Loading all 5 fold models...\n",
            "\n",
            "Model for fold 1 not found in Colab.\n",
            "Please upload: resnet50_fold_1_best.pth\n",
            "Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb449082-ad30-4237-bc18-1efa5cfc3016\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb449082-ad30-4237-bc18-1efa5cfc3016\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_1_best.pth to resnet50_fold_1_best.pth\n",
            "Uploaded and moved to: notebooks/models/resnet50_fold_1_best.pth\n",
            "  Loaded Fold 1 model\n",
            "\n",
            "Model for fold 2 not found in Colab.\n",
            "Please upload: resnet50_fold_2_best.pth\n",
            "Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ee0731f6-37fa-40e1-b5f5-901c8d69c1cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ee0731f6-37fa-40e1-b5f5-901c8d69c1cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_2_best.pth to resnet50_fold_2_best.pth\n",
            "Uploaded and moved to: notebooks/models/resnet50_fold_2_best.pth\n",
            "  Loaded Fold 2 model\n",
            "\n",
            "Model for fold 3 not found in Colab.\n",
            "Please upload: resnet50_fold_3_best.pth\n",
            "Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7d01ece0-5ca3-44c0-99ea-7de3b6a8d28f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7d01ece0-5ca3-44c0-99ea-7de3b6a8d28f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_3_best.pth to resnet50_fold_3_best.pth\n",
            "Uploaded and moved to: notebooks/models/resnet50_fold_3_best.pth\n",
            "  Loaded Fold 3 model\n",
            "\n",
            "Model for fold 4 not found in Colab.\n",
            "Please upload: resnet50_fold_4_best.pth\n",
            "Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2e7fb34-d573-428e-bbde-f2739496e4ae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2e7fb34-d573-428e-bbde-f2739496e4ae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_4_best.pth to resnet50_fold_4_best.pth\n",
            "Uploaded and moved to: notebooks/models/resnet50_fold_4_best.pth\n",
            "  Loaded Fold 4 model\n",
            "\n",
            "Model for fold 5 not found in Colab.\n",
            "Please upload: resnet50_fold_5_best.pth\n",
            "Location on your Mac: /Users/neerajkumar/Downloads/MediScan-AI/models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-287a924b-16b6-49e0-a6cc-34b07a0e71de\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-287a924b-16b6-49e0-a6cc-34b07a0e71de\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_5_best.pth to resnet50_fold_5_best.pth\n",
            "Uploaded and moved to: notebooks/models/resnet50_fold_5_best.pth\n",
            "  Loaded Fold 5 model\n",
            "\n",
            "Running ensemble prediction on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Ensemble predicting:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7b6e3d3403d439b8f29a68a20c06f95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ENSEMBLE RESULTS]\n",
            "Accuracy:  0.8397\n",
            "Precision: 0.8396\n",
            "Recall:    0.8397\n",
            "F1-Score:  0.8366\n",
            "\n",
            "[COMPARISON]\n",
            "Single Best Model: 0.8526\n",
            "Ensemble (5 models): 0.8397\n",
            "Improvement: -0.0128 (-1.28%)\n",
            "\n",
            "[PER-CLASS PERFORMANCE]\n",
            "  NORMAL          Prec: 0.838, Rec: 0.709, F1: 0.769\n",
            "  PNEUMONIA       Prec: 0.840, Rec: 0.918, F1: 0.877\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAJOCAYAAAD2yLKXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgYZJREFUeJzt3Xd4FGXXx/HfbpJNIZQQIPQOARNCL0aKIKiEDoKFIkVBpIiigNjAhqCoFH0E6UVUCE1pihRFIx0iEDpI6CEhkJCyKfv+wcvKkgQSSHZD+H6ea6+Hmbln5swG4tmzZ+4xWCwWiwAAAADYhdHRAQAAAAAPEhJwAAAAwI5IwAEAAAA7IgEHAAAA7IgEHAAAALAjEnAAAADAjkjAAQAAADsiAQcAAADsiAQcAAAAsCMScACZcvr0afn6+lpfW7duzdR+W7dutdnv9OnTORzp/SEiIkJvvvmmmjRpooceesj6/qxfv95uMbRo0cJ63ilTptjtvA+qUaNGWd/vnj17OjocAA7k7OgAgNxi69at6tWr1x3HderUSZ988okdIsK9CA8P1w8//KBt27bp1KlTiomJkaurq8qUKaO6desqKChI9erVc0hsFotFQ4cO1a5duxxy/vuJr6+vzXLhwoW1efNmmUwmm/VXrlxRs2bNFB8fb11XqlQpbdiw4Z7Of+vvhd9++02lS5e+p2MCAAk4gDwlNTVVU6dO1TfffKOUlBSbbcnJyTp48KAOHjyohQsX6tChQw6J8ezZszbJd/PmzVW3bl0ZjUZVqVLFbnG89NJLiomJkSTVrl3bbue9F1FRUfr555/VuXNnm/U//vijTfKdGwUFBVl/viVKlHBwNAAciQQcyEBQUJD8/f3TrLdngoSse//997Vo0SLrsqurq1q1aqVKlSopJSVFx48f1x9//GFNPB3h7NmzNsujR49W2bJl7R5Ht27d7H7O7LBgwQKbBDwlJcXmZ57bxMbGytPTU02bNlXTpk0dHQ6AXIAEHMhAkyZN0lTZbnX69Gk99thj1uV58+bp0qVLmjNnjg4fPiyTyaSHH35Yb775ZpqK12+//abvvvtOYWFhunLlilxdXVW4cGFVrVpVNWvW1Isvviij8b/bNMxms3788UetWbNGR44cUVxcnAoVKqQ6deqoT58+aSqYS5cu1Ztvvmld3rFjhyZNmqS1a9cqNjZWNWrU0BtvvKGAgACFh4fr008/VUhIiJKTk1WnTh2NHDlSVatWve31r169WjNmzNCxY8fk4eGhRx99VMOHD1eRIkXu+P7ekJqaqpUrV2rlypUKCwtTTEyMPD09FRAQoO7du6tZs2aZPtYff/xhk4iVL19eM2bMUJkyZWzGxcfHa/78+Wn2P3HihObMmaO///5b58+flyQVL15cDRs21PPPP69KlSrZjB81apSWLVsmSWrQoIEmTpyoKVOmaOPGjYqOjlaZMmXUp08fm0T31pYKSWrVqpX1z4cOHUrzs7u1Un/zMcaNG2fz93Tp0qVatmyZDh8+rNjYWHl4eKhw4cKqXr266tevr+7du1vHtmjRQmfOnJEkDR48WEOGDLE5z759+zRv3jzt2LFDERERcnZ2VqlSpdS4cWP17t1bxYsXtxnfs2dPbdu2TdL1Vq2XXnpJkydP1p9//qm4uDhVrlxZgwYNUsuWLdO8B5lhNBqVmpqq/fv3a8eOHdYWovXr11uvw8nJKc03Hzds3bpVK1asUFhYmCIiIhQdHS0nJycVK1ZM9erVU+/evW3e2/R+Vjf/e7/RjnZrm8ovv/yi9evXa8mSJQoPD1fTpk319ddfp/n7Mn/+fKWkpKh79+7avXu3JCkgIEDff/+9nJycJEnffPONvvjiC0mSh4eHgoODVbFixbt6/wDkHiTgQDaaNGmSdu7caV1OSEjQunXrdOjQIa1cuVKurq6S0ibH0vX2iGvXrik8PFy//fabevfubR0fFRWlvn37KiwszGafiIgIrVu3Tr/++qtGjRql559/PsPYnn/+ee3fv9+6vG3bNvXo0UNffPGFRo8erejoaOu2LVu2aN++fVqzZo0KFy6c7vFmzZqlTZs22Vzr0qVLtX37dv34448Z7nezhIQEDRw4UH/99ZfN+suXL2vz5s3avHmz+vTpo1GjRt3xWJI0d+5cm+WJEyemSb4lyd3dXf3797dZt2bNGo0cOVKJiYk260+ePKmTJ09q2bJl+uSTT9SmTZt0z33u3Dl17txZERER1nXHjx/XO++8I6PRqKeeeipT13AvpkyZoqlTp9qsu3r1qq5evaqTJ09q+/btNgn47cyZM0fjx49XamqqdZ3ZbNaRI0d05MgRLVmyRF999ZUaNmyY7v4HDhxQ586dde3aNZt1gwcP1uzZs/Xwww9n+foeffRRbdy4URaLRfPnz7cm4Dc+TJlMJjVq1Ei///57uvtv2rRJwcHBNuuSkpJ06tQpnTp1Sj/99JOmT5+uwMDALMd2s9GjR2vHjh2ZGuvk5KTPPvtMHTt2VExMjEJDQzVz5kz1799fhw4dsvl5jh49muQbyCNIwIEM/PHHH7p8+XKa9UFBQRn2b+7cuVM1atRQ48aNtXXrVmuf78mTJ7V+/Xpr8nZzlbZGjRp69NFHlZKSovPnz2vv3r06duyYzXHfeOMNa/KdL18+tW3bVsWLF9euXbv0xx9/KDU1VePGjZO/v7/q1q2bbmxhYWHq1q2bPDw8tHDhQiUlJSkxMVEvv/yynJ2d9dxzzykpKUmLFy+WJEVHR2vJkiVpEtUbNm3apIYNG6pevXratWuXQkJCJMlaTR83blyG7+0NH3/8sTX5dnFxUZs2bVSuXDkdPnxYa9eulcVi0ezZs+Xn56d27drd9lipqanW6qskVatWLd0WovT8+++/GjFihMxmsySpUKFC6tSpkwwGg5YtW6bLly/LbDZr5MiR8vPzU/ny5dMcIzw8XK6urnr22Wfl5uamRYsWKSEhQZI0Y8YMawI+YsQInTp1St9//71135deekkFChTIVKy3c/Pfq8DAQDVo0EDx8fE6d+6cdu7cmebDRUa2b9+uTz75RBaLRZJUsmRJtWnTRnFxcVq6dKni4+MVExOjoUOH6pdfflHBggXTHOPQoUMqWLCgevfurYSEBC1evFgpKSmyWCyaMWPGXSXg5cuXV7NmzbRp0yatX79e58+fV3R0tLZv3y5JGX44usHd3V0NGjRQ1apVVbBgQbm5uVk/7B07dkxJSUn68MMPtXr1akl3/lll1I62Y8cOValSRc2bN5fFYrFWszNSunRpjRkzRsOHD5d0/YNUkyZNNHr0aCUlJUmSnnjiCXXt2jUT7xKA+wEJOJCB1atXW/9DfDN/f/8ME/CAgAB99913cnFxUVJSkpo1a6bIyEhJ0j///GNNEG5OhN5++23VqlXL5jinT5+Wi4uLJOngwYPasmWLddvXX3+tRo0aWZf79++vzZs3W5PVjBLwoUOHauDAgZKkS5cu6eeff7Zue+2119SvXz9J0pEjR7Rnzx5rzBlp3LixZsyYIYPBIIvFohdeeMEa508//aR3331X7u7uGe4fHR1tU40cO3asunTpYrP83XffSbpebb9TAh4dHW3zvmalUrhgwQJr8m00GjV//nxr+02nTp3UoUMHpaamKikpSQsXLtRbb72V7nE+//xza3tFiRIl9PHHH0u63tpyow+4X79+2rp1q01S17Vr12yZWePm658wYYKKFi1qsz08PDxTx5k9e7Y1+c6XL5+WLFkib29vSVKzZs2sH8qio6O1bNky9e7dO80xDAaD5syZo4ceekjS9V78G99Q7Nu3L2sXdpNevXpp06ZNSk5O1nfffWfzjUPPnj3TbS26YejQoUpNTdW+fft07NgxXb16VUWKFFHTpk2tH3qPHTumc+fOqUSJEnf9s6pVq5bmzZtn/QYrM9q2bavff/9dK1askNls1nPPPae4uDhJ19ugPvjgg0wfC0DuRwIOZKOuXbtaE2cXFxeVLl3amoBfuXLFOq5evXrWvt4b/dvlypVT5cqVVa9ePZve01unqrtdm8mNPtL0tG/f3vrnUqVK2Wxr3bq19c9lypSxJuA3x3yrdu3ayWAwSLqebLVr186agCclJenw4cOqWbNmhvvv3btXycnJ1uXRo0dr9OjR6Y4NCwtTfHz8bRP6e3HjeiXJz8/Ppve9atWq8vPzs34YuXnszYoVK2bT21yhQgWb7VevXpWnp2f2BZ2OevXqWduC2rZtq5o1a6pcuXKqUqWKGjZsqHLlymXqODdfY5MmTazJt3Q9AS9cuLCioqLSjL1ZrVq1rMm3ZPt+3O7v1Z088sgjqly5so4ePaoffvjBOvNJnTp15Ofnd9t9//zzT7399ttpboK91fnz5+9plpK+fftmKfm+4d1339Xu3bt16tQpa/JtNBr16aefpvstA4D7Fwk4kIFbb27LjFsT25vnKr5RUZSuV5zDw8P1+++/Ky4uTn/++af+/PNP6/YGDRpo2rRp8vDwyFKyciMpSk+xYsWsf77xISG9bc7O//1auDnmW92clKW3fPXq1dvGmpXrslgsio6Ovm0CXqhQIbm6ulqrwMePH8/08W+OJb0bSG9el9F13e5nL8mmlzqrLBaL9cPOjUp9esaMGaNhw4Zpz549io6O1ubNm222t27dWp9//rnNzb3pycz7cePv2t28H7f7e5UZPXr00JgxY2zuW7jTHP4XLlzQoEGDMjVV4e3e48y42z5tT09PdezYUZMnT7au8/X1Vf369e8pHgC5Dwk4kI1uTl4lWZOmW3l6eurbb7/V+fPntWfPHp08eVJHjx7V+vXrFR8fr23btmnGjBkaOnRomsrX0KFD5ebmluXYbk26bxd3Ztyo7Ge0fKee5luvq3fv3jYfBG6VP3/+2x7PaDSqQYMG+uOPPyRdb905cOCATRU2M7FcunQpzfab12V0Xbe+vxn97DPj1gQ5ISHB+uHj5MmTGe5XokQJ/fDDD/r3338VGhqqf//9V4cPH9Zvv/2m5ORkrVmzRk2aNLFp9UlPwYIFrT/P3PB+3Kpjx4764osvrB8USpQoYTOTTHo2btxok3yPGjVKTz31lPLnz6+jR4/esX88K+72m5rjx4/r22+/tVkXFhamuXPnptvmA+D+RQIOOMDhw4dVoUIFFS9eXE8++aR1/YcffmjtYT1w4ICk61+t38zLy0vPPfdcmmMeOXLknr7az6qffvpJHTp0sPaA//TTT9ZtLi4ud5zCsGbNmjZTxjk7O1v70G92+vRpnThxIlPtG7169bIm4JI0fPhwzZgxI0019sY0hDd6mWvXrq3Q0FBJ0v79+3XkyBHrDXaHDx+2mT3GHg+sufXDxp49e/Twww8rNTVV06ZNy3C/gwcPqmrVqipXrpxNu8nAgQOtT4Q8cODAHRPw2rVra/369ZKu34wcGRlp/YZj8+bNNt+0OOIBPu7u7nrqqac0c+ZMSdKzzz57xw+RN1fLJalz587W93nNmjUZ7nfrcW/cWJvdzGazhg8fbv2QUKlSJWtf+sSJE9WoUSNVq1YtR84NwP5IwIEMZDQLSv78+e/5ASbjx4/XP//8o0aNGqlEiRIqXLiwLl68qKVLl9qcR7o+m8cjjzxibVH54IMP9Pvvv8vf318Gg0Fnz57V7t27dezYMQ0ePNhuj1ffsmWLnn/+edWvX187d+60zoIiXe8Pv1MVsFChQurSpYt+/PFHSddnCtm3b59q164tV1dXXbhwQXv37tWBAwfUqVMnNWnS5I4xNW3aVE8//bR++OEHSdcrikFBQWrZsqUqV66slJQUHTt2zPognhsJePfu3bVo0SKZzWalpqaqR48eNrOg3GgfcXFxyfQ0fvfixs/2RqvGkCFD9Mgjj+jEiRO3fXrnsGHDFBsbq4YNG6pYsWIqVKiQTp06ZTMt352+SZCufxvx22+/yWKx6Nq1a3rqqafUtm1bxcXF2dw4e2O2GEd44YUXrB9OM5oK8Wa39uQPGDBATZo00aFDh7Ru3boM9/Px8bFZHjt2rJo0aSInJye1aNEizXHv1hdffGH90F20aFEtXLhQ7733ntatW2dNzoODg+/q2y8AuQ8JOJCBjGZBKVWqVLY8QfDKlSsZ/off1dVVPXv2tC5/+umn6tevn8LCwpSamqqNGzdq48aN9xzDvWjQoIG2bt2qrVu32qwvVaqUXn/99UwdY/To0Tp9+rR1KsK///5bf//99z3F9d5776lQoUL69ttvlZqaqoSEBJsZX9JTrlw5TZgwwToPeHR0tGbPnm0zxmQy6ZNPPsn0jYz3wsfHR+3atdPKlSslSTExMVq7dq2k6zdB3trbfbOIiIgMr7dQoUKZmsqufv36GjVqlHUe8LNnz2r69Ok2Y/Lnz6/Jkydny/SJd6Nw4cJZeqBPixYtVLVqVR0+fFjS9RuWb9y03KlTJ+sDcm5VunRpPfTQQ9bkeNu2bdbpLkuVKpUtCfhff/1l8/ft/fffl5eXl8aMGaOdO3fq0qVLOnr0qMaPH6/33nvvns8HwPFIwAEHeOGFF1SxYkWFhobq3LlzioqKksFgkI+Pj+rVq6c+ffrYzITi7e2tH3/8UcHBwVq7dq0OHTqkq1evytXVVcWLF5e/v7+aNm1q85S+nDZ48GCdO3dOc+fO1bFjx+Tu7q7mzZvrtddeS3NDZkbc3d01c+ZMrV69WitXrtT+/fsVHR0tZ2dnFStWTNWrV1fjxo31+OOPZzouJycnvfbaa9bq+rZt23Tq1CnFxMTI1dVVZcuWVWBgoIKCgmz2a926tXx9fTV37lyFhIRYn4Tp4+OjRo0aqXfv3mmehJmTPvroIxUpUkSrVq1SVFSUSpUqpa5du6p3794ZzvYxfPhwbdmyRf/8848uXrxofS9LlCihRo0aqV+/fmnacTLSu3dv1a1bV/Pnz9eOHTt08eJFOTk5qVSpUmrSpIl69+59TzOF2JuLi4vmzp2rTz/9VBs2bFBcXJzKly+vnj17KjAwMMMEXLo+L/cnn3yi7du368qVK/d8E+nNLl++rJEjR1qP2blzZ7Vo0ULS9Q8ZH374oV566SVJ0nfffacmTZpYtwO4fxks2fmbBAAAAMBt3X4uKgAAAADZigQcAAAAsCMScAAAAMCOSMABAAAAOyIBBwAAAOyIBBwAAACwIxJwAAAAwI54EA8AG23bttWRI0esy0WLFtWmTZvk7Myvi/vBP//8o1mzZmn79u2Kjo5WgQIFFBAQoF69eikwMDDLxztz5oz14USnT59WYmKi3NzcVKpUKTVq1Ei9evVSmTJlbnuM2bNn65NPPrFZd+jQIbvEDwC5EQ/iAWAVGhqa7qPKv/nmGzVv3twBESErFi9erHfffVepqanpbh80aJCGDh2a6ePt379fvXr1UmxsbIZj8uXLp3nz5snf3z/d7SdOnFDHjh2VkJBgsz69BDy74weA3IoWFABWGT2O+3aP6b7f3C6ZvJ8dOHBAY8aMsSavtWrV0rBhw9S0aVPrmK+++kqbNm3K9DEnTZpkfb8MBoM6duyoYcOGqWXLltYx165d07fffpvu/qmpqXrzzTfTJN/2ih8Aciu+UwYgSTKbzVq1apV1uXz58jp58qQkacOGDbp8+bK8vLzS3ffYsWNasGCBtm7dqnPnzik1NVVFihRRQECA+vbtqxo1aljHWiwWrVu3TsuXL9f+/ft1+fJleXh4qGTJkmrYsKGGDx8uk8mk06dP67HHHrPuN2/ePDVs2NC63LNnT23btk2S1KlTJ2uLQ3r7nTp1St99952OHTumChUqaMWKFQoPD9e8efO0f/9+nTlzRleuXFFycrK8vLzk5+enbt26qUWLFuleb2hoqBYtWqQdO3bo4sWLMhqNKlasmOrUqaOBAweqdOnSatWqlU6fPi1JGjBggF577TWbY4wfP16zZs2SJFWqVEmrV6+WJE2ZMkVTp061jsuoVeNW06ZNU3JysiSpdOnSmj9/vkwmkyTp2Wef1a5duyRdT2IfffTRTB3z1KlT1j8/+uijGj9+vHW5Xbt2Onz4sCQpKioq3f1nz56t3bt3y9nZWU2aNNHGjRvtGj8A5FZUwAFIktavX68rV65Yl8ePHy8XFxdJUlJSkn7++ed091u8eLE6dOhgTXDj4uKUkJCg06dPa/Xq1dq5c6d1bGJiol566SW98sor2rhxoy5evKikpCRduXJFYWFhmjNnTqaqpVkxefJkvf322zpw4IASExOt648ePap58+Zp586dOn/+vOLj45WUlKSLFy9q48aNGjhwoE0ifMPUqVPVrVs3LV26VKdOnVJCQoLi4uJ08uRJLV26VIcPH5bRaNRzzz1n3WfZsmVKSUmxOc66deusf+7cufM9XWNKSop+//1363Lz5s2tyaskPf7449Y/h4aG6tKlS5k6buXKla1/PnjwoA4dOiSz2axdu3bpzJkz1m1NmjRJs++xY8c0adIkSVL//v3l5+dn9/gBILeiAg5Akm2biZ+fn2rVqqWHH37YmhgtW7ZMPXv2tNlnz549Nj27zs7OevLJJ1WhQgVduHBBf/zxh834Tz75xKaFoESJEmrZsqXy58+vo0eP3rZCerd27NihUqVK6fHHH5ebm5u1Wuvk5KTq1avL399fhQsXlqenp+Li4rRr1y5t3bpVkvS///1PXbt2lY+PjyRpzZo1mjJlivXY7u7uCgoKUsmSJXXmzBlt2LDBuu2pp57SlClTFB8fr4sXL2rTpk3WynxoaKg1gXV2dlaHDh3u6RpPnTqluLg463Lp0qVttt96k+ShQ4dUpEiROx731Vdf1Z49exQREaFz586pffv2Nts9PDzUo0cP9e3b12Z9SkqK3nzzTSUmJqpatWp6+eWX9c0339g9fgDIrUjAAejixYv6888/rctt2rSx/v+NBHz//v06dOiQfH19reNmzpxpTb6NRqPmzp2revXqWbebzWZrwnvlyhX9+OOP1m0PPfSQFixYoHz58lnXnTt3Tu7u7tl6baVLl9ayZctUoEABm/VNmzZV06ZNdeLECYWFhSkqKkrOzs5q1qyZQkNDFR8fr+TkZIWEhKhjx46SZNPr7OHhoaVLl6pChQrWdXFxcYqPj5ckFSxYUO3atbNe8+LFi60J+Jo1a6z7NGnSREWLFr2na7z5mwtJ8vT0tFm++T2WpOjo6Ewdt1KlSgoODtaQIUO0d+/eNNsbNmyoNm3apJkhZ+bMmdq7d69cXFxsvkmxd/wAkFuRgAPQihUrrC0SBoNBQUFBkqSWLVvK1dXV2rqxdOlSvfnmm9b9bm4vady4sU3yLUkmk0nFixeXdL1afqPHV5JefPHFNIlViRIlsvGqruvevXua5Fu63iv++uuva/fu3bfd/8KFC5Kk+Ph4HThwwLq+Q4cONsm3dD0p9/DwsC736NHDmoD//vvvunDhgnx8fGzaT7p06WJzjCFDhmjIkCGZvLr03Tq51d1OdnXkyBH1799fZ8+elcFg0OOPP66qVatqz549+uOPP7Rx40aFhIRo5syZ1p/9sWPHrN8SvPTSS6pWrZrD4geA3IoecAA27Se1a9e2JsKenp42N7z99NNPNkn0zZXLW9sGbnVrlfNO4291axJmNpsztV/FihXTXT9o0KA7Jt83n+fq1as2MWQmfl9fXzVo0EDS9baMpUuXau/evdb2k8KFC2fLDYWFChWyWb527dptlzO6mfZWI0eO1NmzZyVdv9F18uTJGjx4sGbMmGG9ITYhIUETJ0607vPxxx/LbDbLz89PL730kkPjB4Dcigo48IDbu3evjh07Zl3etWuXTZvJzSIjI7V582ZrK0XBggUVGRkpSdYZPzJSsGBBm+XTp08rICAgw/FGo2194OYbKFNTU21m6Lid9Fpajh8/roMHD1qX27ZtqxEjRqhYsWIyGAx6+OGH08zsUaBAARkMBmsSfqfrveHm2VqCg4Nt2ifat29/x/aMzChTpow8PDysfdS3xnbre1W1atU7HjMmJkb79++3Lt88k40k+fv7W3vlb34vb9wguX///tveeHnj79ihQ4dyJH4AyM2ogAMPuKVLl2Zp/M3V8rp161r//Oeff9q0pEhScnKytYWjVq1aNr3CM2bMsPZL33DhwgUlJSVJUpq2kT179lj//OOPP2Y49V1m3NpD/OSTT8rHx0cGg0Fbt25N99ju7u566KGHrMsrVqzQv//+azMmISHB+oHkhscee0wlS5aUJIWHh2vRokXWbbe2n0jXpyH09fW1vjLDyclJzZo1sy5v3LjRWrm/Me3jDTVr1rS5gbFnz57Wc40aNcq6/tZZW/755x+b5X379ln/7Orqmqk4cyJ+ALgfUQEHHmCJiYnW+ael620V6VWlDx8+rKNHj0qSNm3apKioKBUuXFj9+vXT+vXrlZqaqpSUFD3//PPWWVAuXbqkLVu2qHv37urdu7cKFiyobt266bvvvpN0vULapk0bPfbYYypQoIBOnjypX3/9VVu2bJGLi4s8PT1t5iL/5ptvFBYWpoSEBP3999/3dN3lypWT0Wi03kD60UcfKSwsTNHR0bf9QPLiiy9q2LBhkq7fcNmxY0frLCjnz5/Xxo0bNWbMGJsH1Tg5OenZZ5+1tmncqOT7+/tnayW3f//++vXXX5WcnKzTp0+rV69eatasmXbu3GlzA+XLL7+cqeMVKlRIVatWtc71vWzZMsXFxalq1aravXu3tfotXe//vyEwMFDlypVLc7yjR4/afNPyxBNP5Gj8AJCbkYADD7D169fr6tWr1uVXXnklzVRzkhQSEqLevXtLuj4n+E8//aTnn39etWrV0vvvv6+xY8cqKSnJui0jo0aN0pkzZ7R582ZJ0pkzZzRv3rwMx7/wwgt6++23JV1vO7kxTWGZMmXk4uKi48ePZ/maJcnb21vdunXT999/L+n67CtfffWVJOnhhx/W8ePHrZX7m7Vu3VrHjh3T1KlTZbFYFBcXpyVLltzxfF27dtXUqVNt2mjude7vWz300EN677339N577yk1NVW7d+9O0+P+8ssvZ6nn/L333tOLL76ouLg4WSwWrV27VmvXrrUZU7JkSQ0fPty6PHLkyHSPdesDhiZPnpzj8QNAbkULCvAAu7namz9/fpsHntysUaNGKlWqlHX55jaUrl27asWKFXr22WdVsWJFubu7y2QyqUSJEnriiSds2lRcXV01bdo0ffnll2revLmKFi1qrXZXrVpVvXr1kpubm82xP/zwQ1WqVEkuLi4qWrSonn32WS1evPie2xDeeecdDR06VKVKlZKLi4tKliypfv366Ztvvkkzrd7NBg8erB9//FGdOnVSmTJl5OrqKnd3d5UpU0YdOnRQlSpV0uzj5eWltm3b2rwP7dq1u6f409OtWzf98MMPat26tfW99fLy0qOPPqpZs2bplVdeydLx6tWrp5UrV6pnz56qWrWqPDw85OTkJE9PT/n7+2vw4MFasWJFts1ek93xA0BuZbAwvxMA5Ljp06db21DatGmjzz//3MERAQAchRYUAMghEREROnbsmM6ePauZM2da13fv3t2BUQEAHI0EHAByyB9//GHz4CLp+owrN7flAAAePCTgAJDDjEajihcvrjZt2mjw4MGODgcA4GD0gAMAAAB2xCwoAAAAgB2RgAMAAAB2RAIOAAAA2FGevAmzwqurHB0CAGjRoEccHQIAqFHlQo4OwYZ77Zy9GT1+99Q7D3IwKuAAAACAHeXJCjgAAAByKQP1X94BAAAAwI6ogAMAAMB+DAZHR+BwVMABAAAAOyIBBwAAgP0YjDn7ugsLFy5UixYtVKNGDXXt2lWhoaEZjk1KStLUqVPVsmVL1ahRQ+3bt9fvv/+epfORgAMAAOCBtXr1ao0bN06DBg3SsmXLVK1aNfXr10+RkZHpjv/yyy/1ww8/6J133tHq1av1zDPPaPDgwTpw4ECmz0kCDgAAAPsxGHL2lUWzZ89Wt27d1KVLF1WuXFljx46Vm5ubgoOD0x2/YsUKvfTSS2rWrJnKlCmj5557Ts2aNdOsWbMyfU4ScAAAADyQzGaz9u/fr8DAQOs6o9GowMBA7d69O919kpKSZDKZbNa5urpq165dmT4vs6AAAADAfnJ4HnCz2Syz2WyzzmQypUmaJeny5ctKSUmRt7e3zXpvb28dP3483eM3btxYc+bMUf369VW2bFmFhITo119/VUpKSqZjpAIOAACAPGPatGmqW7euzWvatGnZdvy33npL5cqVU+vWreXv76/3339fnTt3ltGY+bSaCjgAAADsJ4fnAR8wYID69Oljsy696rckeXl5ycnJKc0Nl5GRkSpSpEi6+xQuXFhff/21EhMTFR0drWLFiumzzz5TmTJlMh0jFXAAAADYTw5PQ2gymeTp6WnzyigBN5lM8vPzU0hIiHVdamqqQkJCVLt27dtehqurq3x8fJScnKxffvlFjz32WKbfAirgAAAAeGD16dNHI0eOlL+/vwICAjR37lzFx8erc+fOkqQRI0bIx8dHw4cPlyTt3btXFy5cUPXq1XXhwgVNmTJFqampeuGFFzJ9ThJwAAAA2E8uexR9UFCQoqKiNHnyZEVERKh69eqaMWOGtQXl3LlzNv3diYmJ+vLLLxUeHi4PDw81a9ZMEyZMUIECBTJ9ToPFYrFk+5U4WIVXVzk6BADQokGPODoEAFCjyoUcHYIN94dH5ejx40M+ydHjZwcq4AAAALCfHJ6G8H7AOwAAAADYERVwAAAA2E8u6wF3BCrgAAAAgB1RAQcAAID90ANOBRwAAACwJyrgAAAAsB96wKmAAwAAAPZEBRwAAAD2Qw84FXAAAADAnqiAAwAAwH6ogFMBBwAAAOyJCjgAAADsx8gsKCTgAAAAsB9aUGhBAQAAAOyJCjgAAADshwfxUAEHAAAA7IkKOAAAAOyHHnAq4AAAAIA9UQEHAACA/dADTgUcAAAAsCcq4AAAALAfesCpgAMAAAD2RAUcAAAA9kMPOBVwAAAAwJ6ogAMAAMB+6AGnAg4AAADYExVwAAAA2A894CTgAAAAsCNaUGhBAQAAAOyJCjgAAADshxYUKuAAAACAPVEBBwAAgP3QA04FHAAAALAnKuAAAACwHyrgVMABAAAAe6ICDgAAAPthFhQq4AAAAIA9UQEHAACA/dADTgUcAAAAsCcq4AAAALAfesCpgAMAAAD2RAUcAAAA9kMPOBVwAAAAwJ6ogAMAAMB+6AEnAQcAAID9GEjAaUEBAAAA7IkEHAAAAHZjMBhy9HU3Fi5cqBYtWqhGjRrq2rWrQkNDbzt+zpw5euKJJxQQEKBmzZrp448/VmJiYqbPRwIOAACAB9bq1as1btw4DRo0SMuWLVO1atXUr18/RUZGpjv+p59+0sSJEzV48GCtXr1aH330kVavXq3PP/880+ckAQcAAID9GHL4lUWzZ89Wt27d1KVLF1WuXFljx46Vm5ubgoOD0x2/e/du1alTR+3atVPp0qXVuHFjtW3b9o5V85uRgAMAACDPMJvNio2NtXmZzeYMx+7fv1+BgYHWdUajUYGBgdq9e3e6+9SuXVv79++3Jtzh4eHavHmzmjVrlukYmQUFAAAAdpPTs6BMmzZNU6dOtVk3ePBgDRkyJM3Yy5cvKyUlRd7e3jbrvb29dfz48XSP365dO12+fFnPPfecLBaLkpOT9cwzz+ill17KdIwk4AAAAMgzBgwYoD59+tisM5lM2Xb8rVu3atq0aXrvvfcUEBCgU6dO6aOPPtJXX32lQYMGZeoYJOAAAACwm5yugJtMpkwn3F5eXnJyckpzw2VkZKSKFCmS7j6TJk1S+/bt1bVrV0mSr6+v4uLi9O6772rgwIEyGu/c4U0POAAAAB5IJpNJfn5+CgkJsa5LTU1VSEiIateune4+CQkJaZJsJycnSZLFYsnUeamAAwAAwG5y25Mw+/Tpo5EjR8rf318BAQGaO3eu4uPj1blzZ0nSiBEj5OPjo+HDh0uSmjdvrtmzZ+uhhx6ytqBMmjRJzZs3tybid0ICDgAAgAdWUFCQoqKiNHnyZEVERKh69eqaMWOGtQXl3LlzNhXvgQMHymAw6Msvv9SFCxdUuHBhNW/eXK+++mqmz2mwZLZWfh+p8OoqR4cAAFo06BFHhwAAalS5kKNDsFHw2fk5evwri3rm6PGzAz3gAAAAgB3RggIAAAD7yV0t4A5BAg4AAAC7yW03YToCLSgAAACAHVEBBwAAgN1QAacCDgAAANgVFXAAAADYDRVwKuAAAACAXVEBBwAAgN1QAacCDgAAANgVFXAAAADYDwVwKuAAAACAPVEBBwAAgN3QA04FHAAAALArKuAAAACwGyrgVMABAAAAu6ICDgAAALuhAk4CDgAAAHsi/6YFBQAAALCnXJ2AHzx4UP7+/o4OAwAAANnEYDDk6Ot+kKsTcElKSUlxdAgAAABAtqEHHAAAAHZzv1Spc1Kur4ADAAAAeYlDK+CxsbH3tB0AAAD3FyrgDk7A69Wrd9sfgsVi4YcEAACAPMWhCfi8efMceXoAAADYGcVVByfgDRo0uOOY6OjonA8EAAAAsJNcexPmli1b9Morr6hp06aODgUAAADZxZDDr/tArpqG8MyZMwoODtby5ct15coVNW3aVOPHj3d0WAAAAEC2cXgCbjab9euvv2rx4sXatWuXAgMDdf78eS1btky+vr6ODg8AAADZiB5wByfgH3zwgX7++WeVL19e7du31xdffCEvLy/5+fnJycnJkaEBAAAAOcKhCfiiRYv04osv6sUXX5Snp6cjQwEAAIAdUAF38E2YEyZMUGhoqJo0aaJhw4Zp48aNSklJcWRIAAAAQI5yaAW8bdu2atu2rcLDw7Vs2TK9//77io+PV2pqqo4eParKlSs7MjwAAABkMyrguWQawjJlymjo0KHasGGDPv30Uz3++ON644031LRpU3344YeODg8AAADZhWkIHT8Lys0MBoOaNGmiJk2aKDo6WsuXL9fSpUsdHRYAAACQbXJVAn6zQoUKqXfv3urdu7ejQwEAAEA2oQXFwQn41KlT7zjGYDBo0KBBdogGAAAAyHkOT8CLFSsmb29vWSyWdMeQgAMAAOQdVMAdnIA3bdpUf//9t/z9/dWlSxc1b95cRmOuuC8UAAAAyBEOTcCnT5+uCxcuaPny5ZowYYLee+89dejQQV26dFHFihUdGRrucz0fKaf+LSqqaH5XhZ29qjFL92vvqSvpjl00qJEaVfZOs37DgYvq9+126/KrT1bVMw+XUQE3F+04eVnvLP5HJy/FWbf7lS6gUW2rKaBsIaWkWrQ29Lw+XH5AcWbmtgceROt/Xqw1wQt15XKkylSooh4vDVclX790x25au1x/blit0yePS5LKV66mp54faDP+yuVI/Tj7K+3bvVVx12Lk61dbPV4aruKlylrHbFyzTH9v/kUnjx5UQnycvv5hvfJ55s/ZCwWyiAp4LpiG0MfHRwMGDNC6dev0xRdfKCoqSk899ZSeeeYZJSQkODo83Ifa1CqhtzpW16R1R9R24haFnY3R3AEN5e1pSnf8S7N3qv67662vx8dvVnJKqlbvOWcdM6BFRfVuWl5vL96nTl/+qfjEZM19qaFMztf/CRUr4KoFLzXUyUtx6vTFn+o9bZuqFPfUZ8/VtMs1A8hdtv7+qxZ9O0kdnuunsZPnqkyFyvrsnVd0NToq3fEH/9mlRk0f16hxX+udiTNUuGgxffbOUEVduihJslgsmvThCF08f0avvPOp3p88X97FimvCW0OUmBBvPY45MUE16jRSu2697XGZAO6SwxPwm9WoUUMNGzZUpUqVFBYWpuTkZEeHhPvQC49W0A8h4Vqy7bSOXojVW4v/Ubw5RV0blkl3/JW4JF2KSbS+GlctovikFK3e+18C3rdZBU395ah+3XdBB8/FaPh3e+VTwFWP1/CRJD3mV0zJqRa9G7xPxyOuKTT8it5evE+ta5ZQuSIedrluALnH2mWL1OzJDmraqp1Kla2o3oNHyeTmpt9/+Snd8S+98b4ea/uUylWqqpJlyqvf0LeUmpqqA3t3SJIunA3XsYP79PygkapY9SGVKF1Ozw8aKbM5USGbf7Ee54mOz6ptt+dVqZq/Xa4TuBsGgyFHX/eDXJGA7969W2+//bYeeeQRzZ8/Xx07dtQff/whT09PR4eG+4yLk0H+pQtqy+FL1nUWi/TnkUuqU65Qpo7RrWEZ/bz7nOL/v3WkjLe7ihVwszlmTEKy9vwbrTrlvSRJJmcnmZNTdfO9xAlJ1/evV6HwPV4VgPtJclKSTh49KL9aDazrjEaj/GrV19GD/2TqGImJCUpJSZFn/gKSpKQksyTJxfTfN3lGo1EuLi46sn9vNkYPwB4cmoB/++23CgoK0ssvvywPDw8tXLhQwcHB6t69uwoUKODI0HCf8spnkrOTUZdiEm3WX4pJVNECrnfcv2bZgqpWsoB++PuUdV3R/G7XjxF7yzFjE1U0//Vj/nXkkooWcFX/5hXl4mRQAXdnjWxbTdL19hQAD46Yq9FKTU1RwUK2H74LFiqsK5fTb0G51Y+zv1KhwkX0UK36kqQSpcvLu2hxLZ7zta7FXFVyUpJWLZ6nqEsXFX350h2OBuQyPAnTsTdhTpw4USVLllTr1q1lMBi0bNmydMe9+eabdo4MD6puDcvo4NmrGd6wmZEj52P1+nd79XaH6nqjja9SLBbN/f2kIq4mKDWDKTYBID0//zhXW3//VaM++Vom0/UP8M7Ozhry1ieaNekjvfxMKxmNTvKrVV8B9R4Wv2KA+49DE/D69a9/sj9y5EiGY+6XXh7kDpevmZWckqoi+W2rzkXyuyriamIGe13nbnJS29ol9cXawzbrI2Ku3wxcxNP2GEU8XXXg7FXr8spdZ7Vy11kV8TQpzpwii6R+j1ZUeGScADw48hcoJKPRSVduueHySnSUCnrdviVtdfACrVoyTyM+mqqyFarYbKtQpbo+mLpAcddilZycpAIFvTT21b6qUKVatl8DkJNyY263cOFCzZw5UxEREapWrZreeecdBQQEpDu2Z8+e2rZtW5r1zZo10/Tp0zN1Pocm4PPnz3fk6ZEHJaVYtO/0FT1StYh+3XdBkmQwSIFVvDVvy7+33TeoZgm5Ohu1fMcZm/XhkfG6eDVBj1T1Vtj/J9yers6qVa6QFvyV9piXYq/3anZtUFqJSSn64xBfDwMPEmcXF5WvXE0H9mxX3YebSdL1Gyr3bFfLtl0z3G/Vkvn66YfZev2DSapQpXqG4zzyXb8/6vyZUzpxNEyde/bP3gsAHjCrV6/WuHHjNHbsWNWsWVNz585Vv379tHbtWnl7p52meMqUKUpKSrIuR0dHq0OHDnryySczfU6HJuCZ8c8//6hGjRqODgP3kRmbTmjiczUVGh6tvf9eUd9m5eVhctaSreGSpInP1dT5Kwn6dNUhm/2eblRGv/xzQdFxSWmOOWvzCQ1uVUUnI64pPCper7WuqgtXE/XLPxesY3o1LqedJy8rLjFFjasW0Zvtq2vCzwcVk8BsPsCD5slOz+rbz99XhSrVVbHqQ1q34nslJiSoSau2kqRpE8fIy7uouvW+/qTnVYvnaemC6XppxPsqUqykoqMiJUlu7u5yc78+k9K2P35T/oKF5F20uE6fPKqF079Q3UZNVaNOI+t5o6MideVypC6cOy1JOn3yqNzc88m7mI888xe051sAZCi3VcBnz56tbt26qUuXLpKksWPHatOmTQoODlb//mk/4BYqVMhmedWqVXJzc7v/EvBr167JyclJbm5u1nVhYWGaNGmSNm/erLCwMAdGh/vNqj3n5O1p0mtPVlWRAq4KO3NVvadts1amS3q5p+nLrlg0n+pXLKye/9ua7jGnbTguD5OzPu5WQwXcXbT9xGX1nrZN5uRU65iaZQtp2JNV5eHqpOMXrumtxf9o2S3VdAAPhoZNW+nqlWgtXTBdVy5HqmzFqnr9/S9V0Ot6NS0q4oKMhv/mQdiweqmSk5M09WPbe546PveCOnV/UZIUffmSFs34Uleio1TIq4geeay1OjzTz2b8xjVLtfy7Gdblj0e+JEl6Ydg71uQfcLTclH+bzWbt379fAwYMsK4zGo0KDAzU7t27M3WM4OBgtWnTRh4emZ922GCxOO72jXPnzmnYsGEKDQ2Vk5OTunfvrmHDhum9997T6tWr1apVK/Xu3Vs1a2btYSYVXl2VQxEDQOYtGvSIo0MAADWqXMjRIdio/PqaHD3+gY8fk9lstllnMplkMqV9IN+FCxfUtGlTff/996pdu7Z1/YQJE7R9+3YtXrz4tucKDQ1V165dtXjx4gx7xtPj0Ar4hAkTlJiYqLfeeku//PKL5s2bpx07dqhmzZpav369ihcv7sjwAAAAkM1yugVl2rRpmjp1qs26wYMHa8iQIdl+riVLlqhq1apZSr4lByfg27dv19SpU1WrVi21bt1ajzzyiNq1a6fevXs7MiwAAADcpwYMGKA+ffrYrEuv+i1JXl5ecnJyUmRkpM36yMhIFSlS5LbniYuL06pVqzR06NAsx+jQB/FERkaqdOnSkiRvb2+5u7uradOmjgwJAAAAOchgyNmXyWSSp6enzSujBNxkMsnPz08hISHWdampqQoJCbFpSUnP2rVrZTab1b59+yy/Bw6/CdNo/O8zgMFgkIuLiwOjAQAAwIOkT58+GjlypPz9/RUQEKC5c+cqPj5enTt3liSNGDFCPj4+Gj58uM1+S5YsUcuWLeXl5ZXlczo0AbdYLHriiSesvUBxcXHq1KmTTVIuKd3JzgEAAHD/yW3TEAYFBSkqKkqTJ09WRESEqlevrhkzZlhbUM6dO5cmNz1+/Lh27typWbNm3dU5HZqAjxs3zpGnBwAAANSjRw/16NEj3W3pPTiyYsWKOnToUDqjM8ehCXinTp0ceXoAAADYWS4rgDuEw3vAJSkhIUF//vmnTp48KUmqUKGCAgMDbR7MAwAAAOQFDk/Af/vtN7399tu6fPmyzXovLy999NFHatGihYMiAwAAQHYzGimBO3Qawl27dumVV15R/fr1tWjRIm3btk3btm3Td999p3r16mno0KHas2ePI0MEAAAAspVDE/D//e9/6ty5syZPnqzatWurQIECKlCggOrUqaMpU6aoc+fO+uqrrxwZIgAAALJRTs8Dfj9waAK+d+9ede/ePcPtzz33HBVwAAAA5CkO7QFPSEiQp6dnhtvz58+vxMREO0YEAACAnJTb5gF3BIdWwMuVK6e///47w+0hISEqV66cHSMCAABATqIFxcEJeJcuXTRhwgRt3rw5zbZNmzbp008/tT4GFAAAAMgLHNqC0qtXL+3atUsDBgxQhQoVVKlSJVksFh07dkz//vuvWrZsqeeff96RIQIAACAb0YLi4ATcaDRq8uTJWr16tX766ScdP35c0vXHew4ZMkRt2rRxZHgAAABAtnP4g3gkKSgoSEFBQY4OAwAAADmMCriDE/Bq1ard8YdgMBh04MABO0UEAAAA5CyHJuBTp07NcNuePXs0f/58paam2jEiAAAA5CQK4A5OwFu2bJlm3fHjxzVx4kRt3LhR7dq109ChQx0QGQAAAJAzckUPuCRduHBBU6ZM0fLly9W4cWMtX75cVatWdXRYAAAAyEb0gOeCBDwmJkbffPONFixYoOrVq2vOnDmqV6+eo8MCAAAAcoRDE/Bvv/1WM2bMUJEiRTRx4sR0W1IAAACQd1AAd3ACPnHiRLm5uals2bJavny5li9fnu64292sCQAAANxPHJqAd+zYkT4gAACABwi5n4MT8E8++cSRpwcAAADszuE3YQIAAODBQQFcMjo6AAAAAOBBQgUcAAAAdkMPOAk4AAAA7Ij8mxYUAAAAwK6ogAMAAMBuaEGhAg4AAADYFRVwAAAA2A0FcCrgAAAAgF2RgCNPq+ASpWYex3L8PMWcYtTa82COnwdA3nDu5CHt+WP1PR8nOcms31fMkTkhPhuiAuzDYDDk6Ot+QAsK8jCL6rid1m/XKkuSarudUVmXaBU0xuuguZi2xZdNM76G63n5ukbI1ZCsuFQX/RFXQZdSPCVJRqWqjtsZVTRFycWQothUV/12rbJiU111MSW/Ui0GlXG+rPBkLztfJ4D7icVi0ZG9f6l203bWdaeP7tOJAzuVGBcrFzd3Va/bTMXKVJIkXb54Rod2bdG1q1FycnZRyQrVVaVWoAwGg5xdTCpZoZqO79+manWbOeqSAGQRCTjyrNLOV5RocVZ0qock6WqKq3Ykl1ZVU0S64+u4nZGPc6zWxVZVTKqr8hnMStV/n6Qbe5yUk1L1U0x1xVtcVNCYILPFybr9WJK3qrteJAEHcFsRZ07IxeSm/F5FJEnhR/7Rvwd3q2bj1srvVVTmhDilJCdLkiypqdq9+WeVr15HFR7qqoS4WG1fHyx3zwIqU6WGJKlUxYf01+qFqlIzUE7OLg67LiCz7pMidY6iBQV5VhmXaJ1Lzm9dPpZURGeSCypJTmnGmgzJ8nO9oD/jyism1U2SQdcsroq3mCRJhYzxKuMSrT/jy///OoOupLrLbPnvM+zZpAIq7hwrZ6Xk9KUBuI9FnDmhwj5lJF1PsI+G/q1q9ZqpQOFiMhgMcnXPJ4/8BSVJSUlmJZkTVLJidRmMRrl7FlDh4mUUE33Jejx3zwJycXVX1IUzDrkeAFlHBRx5VmGnOB0yF8vU2KJOsUqRURVcouTrGqFUGXTCXFi7E0oqVUb5OMcoNtWk2m5nVMHlsswWJx02F9G+xBLWY8RZTEqRQV5O8Yr4/7YVALjV1csR1ur1tZjLMifE6WrURe3f+pssqRYVKVlO1eo2kbOLq0yubipV6SGdObZfFfzqKeFajKLOh6t6/eY2x/QsWFgxlyNUtFR5B1wRkDX3S592TiIBR57lakhRkiVzX/K4GlJkMqSogFOCll71l6shWY95HlWSxajQxJJyNSTLyylBp5MKafHVAOU3JqqV52HFpZp0PMnbehyzxUkmQ3JOXRKAPCDZnCBnl+vfriUlJkiSIs+H6+Enn5Uk7f1zjQ7u/F3+jVpJkoqXrar9W9fr2D9bZbFYVLZqTRUpWc7mmM4uJiWZE+14FQDuBS0oyLMSLU5yMaRmamzy//9T2JNQUsly0jWLq8ISi6mMS/T/b3dSqkXanVBSKTIqOtVdR81FrNtvMBlSbNpSAOBWziY3JSeZJUlOztcT8Yp+9WRyc5fJzV0V/eop4vQJSdK1q5e1e/NP8q3bVC2fGaxHO7+g2KtROrznT5tjJieZ5WJyte+FAHfJYMjZ1/2ABBx5VlSKhwoaMzc1V1SKxx22u9/xGB4Gs5xk0eVMjAXw4CrgVVTXrlyWJOUr4CWjU9r7Um6Iib4kVw9PFS9bRUajUa7u+VSqQnVdOnPSZlzslSjl9yqak2EDyEYk4MizwpMKqYRzjHXZoFQ5KVUGWWSQ/v/P1yvksamuOpuUXzXdzslJKXI3mK/PaJJUSJJ0ITm/rqa6qabbWRmUqgLGBFU2XbJul6QSzld1PtlTyenc5AkANxQtVUFRF8IlSU7OzipRvppO7N+ppMQEJZkTdWL/ThUtXVGSVKBwMSXGX9OF8GOyWCwyJ8Tp7ImDNsl2fOxVJSXGy8unlEOuB8gq5gGnBxx52JnkgmpoOKVCxnhFp7rrEY9/VdkUad1e3fWijpq9tSWugiTp97iKCvT4V88U3CuzxUnHzd76J7G4JMkig367VlmB7v/quYJ7lJDqrAOJPjb935VMkTqYyZs+ATy4ipYsr4M7Nism+pLyFyqiavWaKWz7Rv2+YraMTk4qWqqiqtVtKkny8Cyomo1b62jo39oX8ouMTk7yLl7Wul2Szp4IU8mKD8mZKQhxn7hfkuScRAKOPMsig3YllFJNt7PaHFdJW+IqWJPt9CRYXLTh/x/ak56YVDetu+ab7raiTrFyMlh0Kok5wAHcnsFoVJVagTr+zzbVbBIkZ2cX1Xj4cenh9McXK11Rxf6/In6r5CSzzhwPU6MnuuVgxACyGwk48rQTSd46cVOVOqdEpHhqTWy1HD8PgLyhRHlflSif/gf6rHB2Malph973HhBgRxTA6QEHAAAA7IoKOAAAAOyGHnAq4AAAAIBdUQEHAACA3VAApwIOAAAA2BUJOAAAAOwmNz6IZ+HChWrRooVq1Kihrl27KjQ09Lbjr169qrFjx6px48by9/fXE088oc2bN2f6fLSgAAAA4IG1evVqjRs3TmPHjlXNmjU1d+5c9evXT2vXrpW3d9qpjM1ms/r06SNvb29NmjRJPj4+Onv2rAoUKJDpc5KAAwAAwG5yWw/47Nmz1a1bN3Xp0kWSNHbsWG3atEnBwcHq379/mvHBwcG6cuWKvv/+e7m4XH8CbenSpbN0TlpQAAAAkGeYzWbFxsbavMxmc4Zj9+/fr8DAQOs6o9GowMBA7d69O919NmzYoFq1aun9999XYGCg2rZtq2+++UYpKSmZjpEEHAAAAHZjNBhy9DVt2jTVrVvX5jVt2rR0Y7l8+bJSUlLStJp4e3vr0qVL6e4THh6udevWKSUlRdOnT9fLL7+s2bNn63//+1+m3wNaUAAAAJBnDBgwQH369LFZZzKZsu34FotF3t7e+uCDD+Tk5CR/f39duHBBM2fO1ODBgzN1DBJwAAAA2E1O94CbTKZMJ9xeXl5ycnJSZGSkzfrIyEgVKVIk3X2KFi0qZ2dnOTk5WddVrFhRERERMpvNmTo3LSgAAACwm9w0DaHJZJKfn59CQkKs61JTUxUSEqLatWunu0+dOnV06tQppaamWtedPHlSRYsWzXTiTwIOAACAB1afPn30448/atmyZTp27JjGjBmj+Ph4de7cWZI0YsQITZw40Tr+2WefVXR0tD766COdOHFCmzZt0rRp09S9e/dMn5MWFAAAANiNMZdNQxgUFKSoqChNnjxZERERql69umbMmGFtQTl37pyMxv9q1iVKlNDMmTM1btw4tW/fXj4+PurVq5defPHFTJ/TYLFYLNl+JQ5W4dVVjg4BALRo0COODgEA1KhyIUeHYKP1/7bm6PHXDGyYo8fPDlTAAQAAYDd3+7j4vIQecAAAAMCOqIADAADAbiiAUwEHAAAA7IoKOAAAAOzGIErgVMABAAAAO6ICDgAAALvJbfOAOwIVcAAAAMCOqIADAADAbpgHnAo4AAAAYFdUwAEAAGA3FMCpgAMAAAB2RQUcAAAAdmOkBE4CDgAAAPsh/6YFBQAAALArKuAAAACwG6YhpAIOAAAA2FWmKuAHDx7M9AGrVat218EAAAAgb6MAnskEvGPHjjIYDLJYLOluv7HNYDAoLCwsWwMEAAAA8pJMJeC//fZbTscBAACABwDTEGYyAS9VqlROxwEAAAA8EO7qJszly5frmWeeUePGjXXmzBlJ0pw5c7R+/fpsDQ4AAAB5iyGHX/eDLCfg3333nT755BM1a9ZMMTExSk1NlSQVKFBAc+fOzfYAAQAAgLwkywn4ggUL9OGHH2rgwIEyGv/b3d/fX4cPH87W4AAAAJC3GAyGHH3dD7KcgJ8+fVrVq1dPs95kMik+Pj5bggIAAADyqiwn4KVLl053qsE//vhDlSpVypagAAAAkDcZDTn7uh9k+VH0ffr00fvvvy+z2SxJCg0N1c8//6zp06frww8/zPYAAQAAgLwkywl4165d5erqqi+//FLx8fEaPny4ihUrptGjR6tNmzY5ESMAAADyiPulTzsnZTkBl6T27durffv2io+PV1xcnLy9vbM7LgAAAORB5N93mYBLUmRkpE6cOCHp+ieZwoULZ1tQAAAAQF6V5QQ8NjZWY8eO1apVq6xzgDs5Oal169Z67733lD9//mwPEgAAAHkDLSh3MQvK22+/rdDQUE2bNk07duzQjh079M0332jfvn169913cyJGAAAAIM/IcgV806ZNmjFjhurVq2dd16RJE3344Yd64YUXsjU4AAAA5C33y1SBOSnLFfBChQql22bi6empAgUKZEtQAAAAQF6V5QR84MCB+uSTTxQREWFdFxERoU8//VQvv/xytgYHAACAvIVH0WeyBaVjx442F3Ty5Ek1b95cJUqUkCSdO3dOLi4uioqK0jPPPJMzkQIAAAB5QKYS8JYtW+Z0HAAAAHgA3B816pyVqQR88ODBOR0HAAAA8EC46wfxAAAAAFllvE/6tHNSlhPwlJQUzZkzR2vWrNG5c+eUlJRks33btm3ZFhwAAACQ12R5FpSpU6dq9uzZCgoKUkxMjHr37q1WrVrJYDDQqgIAAIDbMhhy9nU/yHIF/KefftKHH36oRx99VFOmTFHbtm1VtmxZ+fr6au/evTkRIwAAAJBnZLkCfunSJVWtWlWSlC9fPsXExEiSmjdvrk2bNmVrcAAAAMhbmAf8LhJwHx8f60N4ypQpoz///FOS9M8//8hkMmVvdAAAAEAek+UWlFatWikkJEQ1a9ZUz5499cYbb2jJkiU6e/asevfunQMhAgAAIK+4T4rUOSrLCfjrr79u/XNQUJBKliyp3bt3q1y5cmrRokW2BgcAAIC8hWkI76IF5Va1atVSnz59VLNmTX3zzTfZERMAAACQZ91zAn5DRESEJk2alF2HAwAAQB6UG6chXLhwoVq0aKEaNWqoa9euCg0NzXDs0qVL5evra/OqUaNGls7HkzABAADwwFq9erXGjRunsWPHqmbNmpo7d6769euntWvXytvbO919PD09tXbtWutyVmdfybYKOAAAAHAnuW0awtmzZ6tbt27q0qWLKleurLFjx8rNzU3BwcG3vYaiRYtaX0WKFMnSOamAAwAAIM8wm80ym80260wmU7rTZZvNZu3fv18DBgywrjMajQoMDNTu3bszPEdcXJyaN2+u1NRUPfTQQ3rttddUpUqVTMeY6QR83Lhxt90eFRWV6ZPmtLBP2zg6BACQV/3Bjg4BABS/e6qjQ7CR0+0X06ZN09Spttc8ePBgDRkyJM3Yy5cvKyUlJU2ribe3t44fP57u8StUqKCPP/5Yvr6+iomJ0axZs/TMM89o1apVKl68eKZizHQCfuDAgTuOqVevXmYPBwAAAGS7AQMGqE+fPjbrsvNhkbVr11bt2rVtloOCgvT9999r2LBhmTpGphPw+fPnZzlAAAAA4GY5/bj4jNpN0uPl5SUnJydFRkbarI+MjMx0X7eLi4uqV6+uU6dOZTpGbsIEAADAA8lkMsnPz08hISHWdampqQoJCbGpct9OSkqKDh8+rKJFi2b6vNyECQAAALsx5rIHYfbp00cjR46Uv7+/AgICNHfuXMXHx6tz586SpBEjRsjHx0fDhw+XJE2dOlW1atVSuXLldPXqVc2cOVNnz55V165dM31OEnAAAAA8sIKCghQVFaXJkycrIiJC1atX14wZM6wtKOfOnZPR+F/TyNWrV/XOO+8oIiJCBQsWlJ+fn77//ntVrlw50+c0WCwWS7ZfiYMlJDs6AgBgFhQAuUNumwXltZUHc/T4n7evlqPHzw70gAMAAAB2dFcJ+I4dO/T666/r6aef1oULFyRJy5cv144dO7I1OAAAAOQtue1JmI6Q5QR83bp16tevn9zc3HTgwAHrk4ZiY2M1bdq0bA8QAAAAeYfRkLOv+0GWE/D//e9/Gjt2rD788EM5O/93D2edOnUy9bAeAAAA4EGW5VlQTpw4ke4TL/Pnz6+rV69mS1AAAADIm+6TLpEcleUKeJEiRdJ90s/OnTtVpkyZbAkKAAAAyKuynIB369ZNH330kfbu3SuDwaALFy5o5cqVGj9+vJ599tmciBEAAAB5hNFgyNHX/SDLLSj9+/dXamqqevfurfj4ePXo0UMmk0l9+/ZVz549cyJGAAAAIM/IcgJuMBg0cOBA9evXT6dOnVJcXJwqVaqkfPny5UR8AAAAyEN4CM09PIreZDJl6ZGbAAAAAO4iAe/Zs+dtJzmfN2/ePQUEAACAvOs+adPOUVlOwKtXr26znJycrLCwMB05ckQdO3bMrrgAAACAPCnLCfjo0aPTXT9lyhTFxcXdc0AAAADIu+6XmUpyUrb1wbdv317BwcHZdTgAAAAgT7rrmzBvtXv3bplMpuw6HAAAAPIgCuB3kYAPHjzYZtlisSgiIkL79u3Tyy+/nG2BAQAAAHlRlhPw/Pnz2ywbDAZVqFBBQ4cOVePGjbMtMAAAAOQ9RirgWUvAU1JS1LlzZ1WtWlUFCxbMqZgAAACQR3ETZhZvwnRyclLfvn119erVnIoHAAAAyNOyPAtKlSpVdPr06ZyIBQAAAHmcwZCzr/tBlhPwYcOGafz48dq4caMuXryo2NhYmxcAAACAjGW6B3zq1Knq27ev+vfvL0kaOHCgzSPpLRaLDAaDwsLCsj9KAAAA5AnchJmFBPyrr77Ss88+q3nz5uVkPAAAAECelukE3GKxSJIaNGiQY8EAAAAgbzOIEniWesAN90tnOwAAAJBLZWke8CeeeOKOSfi2bdvuKSAAAADkXfSAZzEBHzJkSJonYQIAAADIvCwl4G3atJG3t3dOxQIAAIA8jgp4FnrA6f8GAAAA7l2WZ0EBAAAA7hZF3Swk4AcPHszJOAAAAIAHQpZ6wAEAAIB7QQ94FucBBwAAAHBvqIADAADAbmgBJwEHAACAHRnJwGlBAQAAAOyJCjgAAADshpswqYADAAAAdkUFHAAAAHZDCzgVcAAAAMCuqIADAADAboyiBE4FHAAAALAjKuAAAACwG3rAqYADAAAAdkUFHAAAAHbDPOBUwAEAAAC7IgEHAACA3RgNhhx93Y2FCxeqRYsWqlGjhrp27arQ0NBM7bdq1Sr5+vrq5ZdfztL5SMABAADwwFq9erXGjRunQYMGadmyZapWrZr69eunyMjI2+53+vRpjR8/XvXq1cvyOUnAAQAAYDcGQ86+smr27Nnq1q2bunTposqVK2vs2LFyc3NTcHBwhvukpKTo9ddf15AhQ1SmTJksn5MEHAAAAHaTm1pQzGaz9u/fr8DAwP/iMxoVGBio3bt3Z7jfV199JW9vb3Xt2vWu3gNmQQEAAECeYTabZTabbdaZTCaZTKY0Yy9fvqyUlBR5e3vbrPf29tbx48fTPf6OHTu0ZMkSLV++/K5jpAIOAAAAu8npFpRp06apbt26Nq9p06ZlS+yxsbEaMWKEPvjgAxUuXPiuj0MFHAAAAHnGgAED1KdPH5t16VW/JcnLy0tOTk5pbriMjIxUkSJF0owPDw/XmTNnNHDgQOu61NRUSdJDDz2ktWvXqmzZsneMkQQcAAAAdpPT7RcZtZtkNNbPz08hISFq2bKlpOsJdUhIiHr06JFmfMWKFfXTTz/ZrPvyyy917do1vfXWWypevHimzksCDgAAgAdWnz59NHLkSPn7+ysgIEBz585VfHy8OnfuLEkaMWKEfHx8NHz4cLm6uqpq1ao2+xcoUECS0qy/HRJwAAAA2I3hLh+Wk1OCgoIUFRWlyZMnKyIiQtWrV9eMGTOsLSjnzp2T0Zi9dXuDxWKxZOsRc4GEZEdHAACSV/3Bjg4BABS/e6qjQ7Axd0d4jh7/+XpZn5fb3qiAAwAAwG5yV/3bMZiGEAAAALAjKuAAAACwm6w+rTIvogIOAAAA2BEVcAAAANgN9W8q4AAAAIBdUQEHAACA3dACTgIOAAAAO8ptD+JxBFpQAAAAADuiAg4AAAC7ofrLewAAAADYFRVwAAAA2A094FTAAQAAALuiAg4AAAC7of5NBRwAAACwKyrgAAAAsBt6wKmAAwAAAHaV6xPw6OhoR4cAAACAbGLM4df9INfGuWXLFr3yyitq2rSpo0MBAAAAsk2u6gE/c+aMgoODtXz5cl25ckVNmzbV+PHjHR0WAAAAsgk94LkgATebzfr111+1ePFi7dq1S4GBgTp//ryWLVsmX19fR4cHAAAAZCuHJuAffPCBfv75Z5UvX17t27fXF198IS8vL/n5+cnJycmRoQEAACAHUP92cAK+aNEivfjii3rxxRfl6enpyFAAAAAAu3DoTZgTJkxQaGiomjRpomHDhmnjxo1KSUlxZEgAAADIQQZDzr7uBw6tgLdt21Zt27ZVeHi4li1bpvfff1/x8fFKTU3V0aNHVblyZUeGBwAAgGxmpAlFBovFYnF0EDdYLBZt2bJFS5Ys0YYNG+Tl5aXHH39cb7/9dpaOk5CcQwECQBZ41R/s6BAAQPG7pzo6BBs//XMhR4/froZPjh4/Ozh8FpSbGQwGNWnSRE2aNFF0dLSWL1+upUuXOjosAAAAZJP7pU0kJ+XaB/EUKlRIvXv31sqVKx0dCgAAAJBtHFoBHzdu3B3HGAwGjRo1yg7RAAAAIKcZ6AF3bAJ+4MCBO47haUkAAADISxyagM+fP9+RpwcAAICdUVvNxT3gAAAAQF7k0Ar41KmZmxZn8GCm8gIAAMgLmAfcwQn4+vXrM9xmMBh04sQJJSYmkoADAAAgz3BoAr58+fJ014eFhemzzz7TkSNH1LVrV/sGBQAAgBxDD3guexBPeHi4Jk2apDVr1qhVq1b6+eefVb58eUeHBQAAAGSbXJGAR0VF6auvvtIPP/ygunXratGiRQoICHB0WAAAAMhmVMAdnIDHxcVp1qxZmj17tsqVK6dvvvlGjRs3dmRIAAAAQI5yaALeqlUrXbt2TT169FDbtm0lSQcPHkwzrlq1avYODQAAADmAJ2E6OAGPjIyUJM2YMUMzZ86UxWKxbjMYDLJYLDIYDAoLC3NUiAAAAMhGRvJvxybgv/32myNPDwAAANidQxPwUqVKOfL0AAAAsDNaUHLJLCihoaFatWqVTp48KUkqX7682rZtqxo1ajg2MAAAACCbOTwBnzBhgmbNmiUPDw+VKVNGkrRt2zbNmzdPffv21RtvvOHgCAEAAJBdmIbQwQn4smXLtGDBAr399tt6+umn5eLiIklKSkrSokWL9Nlnn6lKlSrq2LGjI8MEAAAAso1DE/CFCxfqtddeU48ePWzWu7i4qFevXkpJSdGCBQtIwAEAAPIIesAloyNPfvToUT322GMZbm/ZsqWOHj1qx4gAAACAnOXQBNxoNMpsNme4PSkpSUajQ0MEAABANjIacvZ1NxYuXKgWLVqoRo0a6tq1q0JDQzMc+8svv6hz586qV6+eatWqpQ4dOmj58uVZew/uLszs4efnp59++inD7StWrJCfn58dIwIAAMCDZPXq1Ro3bpwGDRqkZcuWqVq1aurXr5/1gZG3KliwoAYOHKgffvhBK1euVOfOnTV69Gj98ccfmT6nQxPwvn37avr06ZowYYIuXbpkXR8REaHx48drxowZ6tu3rwMjBAAAQHYy5PD/smr27Nnq1q2bunTposqVK2vs2LFyc3NTcHBwuuMbNmyoVq1aqVKlSipbtqyef/55+fr6aufOnZk+p0NvwmzevLnefPNNjR8/XrNnz1b+/PklSTExMXJyctKIESPUvHlzR4aI+9T33y3U3NkzdelShKr6VtOo0e+oRkBAhuN/WbdGX02ZpLNnzqhsufIa9trratK0mXV73LVr+vKLidq4Yb2uREerVKnSerZHT3V7+llJ0pXoaH391RSF/LVF58+dk5dXYTV/rKUGDXnF+vcawINlQLemevX5x+TjXUD/HD6j18Yv1o79/6Y71tnZqDf6Pq4ebRuqZLFCOvzvBb09aYV+/SvMOuaROpX0aq+WqvNQWZUoWlDdXp2unzbZfk2ez92kD4d2ULvmASpcMJ9Ono3U14s2a8aSLTl6rUBuYjab07Q4m0wmmUymdMfu379fAwYMsK4zGo0KDAzU7t2773gui8Wiv//+WydOnNDrr7+e6RgdPg94z5491apVK61du9bmQTxPPPGESpQo4djgcF9au2a1PpswTm+/N1Y1atTUwvlzNXBAP634ea28vb3TjN+ze5dGvTFcQ4e9pqbNmmv1qp80bMggfb9kqapUqSpJ+mzCJ9q29W99/MmnKlmqlEL+/FMffzhWxYoW06MtHtPFiIuKuHhRr70+UpUqVdbZs2f04ftjFHHxoiZ+OdnO7wAAR3vq8ToaP7yThnz0g7bvO6nBzzXXyq8HqWbH9xVxOTbN+DEvt9Ozberr5Q++06ETF9QqsLp+mPiimvf+XHsPnZYk5XN31T+Hz2jeihD98Hn/dM87fngXPVq/qvq8NU//no1Uy4era9Kb3XQu4opWbf4nR68ZyKycngd82rRpmjp1qs26wYMHa8iQIWnGXr58WSkpKWnyA29vbx0/fjzDc8TExKhp06Yym80yGo1677339Mgjj2Q6RoPFYrFkevR9IiHZ0RHAkbo/01V+/jU0+u13JUmpqal6/LFmeva5nur3Ytr/aL0xfJji4+M19etp1nU9nu0m32rV9M5770uSOndoqyeebK0BAwdZxzzTtbMaN26iwa+8mm4cv6xbo9Ej39DfO/bI2dnhn3XhAF71Bzs6BDjI7/Ne1879/+rV8YslSQaDQUfXfqD/fb9Zn83+Nc344798pPEz1mnaj79b1y367AXFJ5jV9+15acbH756abgV8x+LRWvLLLn3y7Vrruj8XjtAvfx7Q2K9/zq7Lw30mfvfUOw+yoy1HLufo8RuUy5fpCviFCxfUtGlTff/996pdu7Z1/YQJE7R9+3YtXrw43XOkpqYqPDxccXFxCgkJ0ddff62vvvpKDRs2zFSMDs0Ktm/fnqlx9evXz+FIkFckmc0KO7Bf/V60/SqpUaNAhe5N/6uk0D171PP53jbrAh9prI2/rbcu16pVW5s3blDHzk+pWLFi2r5tq/49eUJvjHwzw1hiY2Ll6elJ8g08YFycnVS7ehl9OusX6zqLxaINWw+pQUCFdPcxuTgrwZxksy4+wazA2pWydO6/955Q22Y1NG95iM5GXFHTelVUpVwxjZiYfi8r4Ag5PQt4Rsl2ery8vOTk5JTmhsvIyEgVKVIkw/2MRqPKlSsnSapevbqOHTum6dOn3x8JeM+ePWX4/+8hMirEGwwGhYWFpbsNuNXl6Iy/SjpxIv2vki5duiRv7yJpxl+K/O/G4FFvvaP333tHj7doKmdnZxkMBr039kPVrZf+h8PLl6M0/Zuv1aXr0/d4RQDuN0W8POXs7KSLUTE26y9GXpVveZ9091kfEqahPVpoy66jOh5+Sc0b+KpDi1pycspaqvLa+MX66p1ndeyXj5SUlKJUS6pe/mCR/tx17K6vB8huxlz0LHqTySQ/Pz+FhISoZcuWkq5Xt0NCQtI8KPJ2UlNTbzu19q0cmoAXLFhQ+fLlU6dOndShQwd5eXk5MhwgQ4sWzldo6B5Nmvo/lSxZUjt37NDHH45V0WLF1OjhQJuxsbGxGjxwgCpWqqSXXqYFAcCdvf7pEn39zrPau/QdWSwWHT99SfNW/q3nOzTK0nFefqaZGtQory6vfKNT56LUuE5lfTnqeg/4xq2Hcih64P7Wp08fjRw5Uv7+/goICNDcuXMVHx+vzp07S5JGjBghHx8fDR8+XNL1HnN/f3+VLVtWZrNZmzdv1sqVKzVmzJhMn9OhCfgff/yh9evXKzg4WDNmzFCzZs3UpUsXNW3a1FoZB7LCq1DWv0oqUqSIIm+qdlvH/39VPCEhQZO//EJfTJ6qps0elSRV9a2mQ4fCNHf2TJsE/Nq1WL084AXly5dPX0z+Si4uLtl4dQDuB5cuxyo5OUXFCtvOgFTMu4DOR17NcJ9ur30rV5OzvAvm09mIK/pwaAedOJP+PMTpcXN10dgh7fT0a99q7Zb9kqR9R84qwLe0hvV8jAQcuUZuy/CCgoIUFRWlyZMnKyIiQtWrV9eMGTOsecO5c+dsHgwZFxensWPH6vz583Jzc1PFihX16aefKigoKNPndGgCbjKZFBQUpKCgIJ09e1ZLly7VBx98ILPZrE6dOmnIkCH0zyJLXEwmVX/IT1v/DlGLx/77Kmnr1hA982z6XyUF1KqlrX//rR69elvX/R3ylwJq1ZIkJScnKzk5ScZbHq9lNDop9abWqdjYWA3s308mk0mTpv5Prq6u2XtxAO4LSckp2h0WruYNfa03SRoMBjVvUFXf/PD7bfdNNCfrbMQVOTsb1fGxWgr+dVemz+vi7CSTi7PN7yVJSklJTfP7C4CtHj16ZNhyMn/+fJvlV199Va++mv4EDJmVa57zXrJkSQ0ePFizZ89W+fLlNX36dMXGpp2qCbiTns/30dIlP2rl8mU6fuyYPnx/jOLj49Wx0/Wvkt56c4QmfTHROr57j176688/NHfOLJ04fkz/+2qK9u/bp2eeu/4P0dPTU/XqN9Dnn32q7du26vTpcK1YtlQ/r1yux/4/yY+NjdVLL/ZVfHycxrz/ka7FxupSRIQuRUQoJSXF7u8BAMeavGCD+nQKVPd2DeVbwUeTRz8tD3dXzVvxtyRpxgc99f6Q9tbx9f3LqUOLmipfyluP1K6klVMHyWg06PM5/90Mns/dpICqpRRQtZQkqXwpbwVULaUyxa+3b8ZcS9DvO47o42Ed1aRuFZUr6a0e7Rqqe9sGWrlxrx2vHrgDQw6/7gO5orxsNpu1bt06BQcHa8+ePWrWrJmmTZumQoUKOTo03IeebB2ky1FR+nrqZF26FCHfatX19bQZ8v7/r5LOnzsno+G/z561atfRuAmfaerkLzXly89Vtlx5fTnlK+sc4JI0/tPPNenLz/XmyNd19coVlShZUoOHvqqu//8gnrAD+/VP6PX/wLVt3comntW//KZSpUrn9GUDyEWW/LJLRbw89e7ANvLxzq/QQ2fUYdBX1hszyxQvrNTU/yrVrq4uem9QW1UoVUSxcYla9+d+9Xtnnq7ExlvH1HmonH6Z8Yp1ecLrXSRJ81f+rf7vLZAk9Ro1S+8P6aA5Hz8vrwIeOnUuSmO++lnfLuZBPEBu4tB5wENDQxUcHKzVq1erVKlS6ty5s9q3b3/PiTfzgAPIDZgHHEBukNvmAd967EqOHr9hpYI5evzs4NAKeLdu3VSyZEn17NlTfn5+kqSdO3emGffYY4/ZOzQAAAAgRzi8BeXs2bP6+uuvM9zOPOAAAAB5BxPdOTgBP3jwoCNPDwAAANidwyvgAAAAeHBQAHdwAj5v3rx01+fPn1/ly5dX7dq17RwRAAAAkLMcmoDPmTMn3fUxMTGKiYlR7dq19b///Y/pCAEAAPIKSuCOTcA3bNiQ4bbw8HC98cYb+vLLLzVmzBj7BQUAAADkoFzzJMxblSlTRsOHD9eff/7p6FAAAACQTQw5/L/7Qa5NwCWpRIkSunTpkqPDAAAAALJNrp4F5fDhwypZsqSjwwAAAEA2YR5wByfgsbGx6a6PiYnR/v379cknn6hjx472DQoAAAA5hvzbwQl4vXr1ZMjgY5DBYNBTTz2l/v372zkqAAAAIOfkynnAPT09Va5cOeXLl8/OEQEAACBHUQJ3bALeoEEDR54eAAAAsDuHzoLy7bffKiEhwbq8c+dOmc1m63JsbCxzgAMAAOQhTEPo4AT8888/17Vr16zLL774oi5cuGBdTkhI0A8//OCI0AAAAIAc4dAWFIvFcttlAAAA5C1MQ5jLH8QDAAAA5DW5+kE8AAAAyFsogOeCBHzx4sXy8PCQJKWkpGjp0qXy8vKSJJv+cAAAACAvcGgCXrJkSf3444/W5SJFimjFihU2Y0qUKGHvsAAAAJBTKIE7NgHfsGGDI08PAAAA2J3DW1AAAADw4Lhf5urOSQ5NwJcvX56pcR07dszROAAAAAB7cWgC/tFHH2W4zWAwKC4uTikpKSTgAAAAeQTzgDs4Ad++fXu66y9evKipU6dq6dKlCgwMtHNUAAAAyCnk37msBzw2Nlbffvut5s2bpypVqmjGjBlq1KiRo8MCAAAAsk2uSMCTkpK0YMECffPNNypUqJDGjRunJ5980tFhAQAAILtRAndsAm6xWLR8+XJNnjxZycnJeu211/TUU0/JycnJkWEBAAAAOcahCXj79u0VHh6uHj166Pnnn5e7u7vi4+PTjPP09HRAdAAAAMhuTEMoGSwWi8VRJ69Wrdp/gaRzS6zFYpHBYFBYWFiWjpuQfM+hAcA986o/2NEhAIDid091dAg29p+5lqPH9yuVL0ePnx0cWgGfN2+eI08PAAAAO2MaQgcn4HXr1tXMmTO1YcMGJSUl6eGHH9bgwYPl5ubmyLAAAACAHGN05Mm/+eYbffHFF8qXL598fHw0b948jR071pEhAQAAIAcZcvh1P3BoBXzFihV677339Mwzz0iS/vrrL/Xv318fffSRjEaHfjYAAAAAcoRDs9yzZ8+qWbNm1uXAwEAZDAZdvHjRgVEBAAAgx1ACd2wCnpKSIldXV5t1zs7OSkpKclBEAAAAQM5y+IN4Ro0aJZPJZF1nNps1ZswYubu7W9dNnZq7ps/B/evA/n06fChMHTt3vafjXImO1o/fL1CfF16Ss3OueKAsgFyseilXVS1p0ortMTl6HpOzQX2ae2ne5suKNztslmHgtpgH3MEJeKdOndKsa9++vQMiwYPAYrHo902/qUvX6/ccLAv+UWfCw5WUZJa7u4cCatVWYOOmkqSoyEht2rBeZ8+EKzk5WUWKFtOjLVqqdJmykqSChQqpZKky2rNrh+o1aOSwawJwf2j2UD4Fb70iSepYv4BKezvLxcmgeLNFof8m6K/DcdaxAx8vLA9Xo248pSPVYtGXqyKt20sXdlZzf09553dSUrJF+8ITtfnA9XmVzckW7TuVoMCqHvptX87OtQzg7jk0AR83bpwjT48HzLGjR+Tu5q6ixXwkSY2bNJNXYW85Ozvr6pUr+vH7BSpYsJD8agQoISFBFStV1pNBbeXm7q7Qvbu1+IfvNODlofLw8JAk1QioqbWrfiIBB3BblXxMijenKuJqiiTpz0PXFBWbopRUqYC7Ud0eLqgrcSnafzrRus/KHVd15Jw5zbEMkro0KqitR+K04Pd4FfAw6tlHCulKXIr2nEyQJO0LT1Cf5l7aHHZNySl2uUQgS5gH3ME94IA9HT18SGXLV7AuFy3m81/7iOH601ijoq5XmUqWKqVaderKI18+GY1G1apdV0aDQREXL1j3L1W6jGJirurSpQi7XgeA+0uVEib9e+m/e5sirl5PviXJ8v8vL0+nTB3L1cUgd5NR+8ITZZF0JS5VJyPMKlrgv3ralbhUxZstKuttyvhAAByK5lU8MC5eOK9aderZrPtlzSr9E7pHycnJKlCwoGrUrJXuvhEXL8hsNsu7SFHrOicnJxXyKqyLF86ryE3rAeBmxQo6a8+JBJt1jwd4qkZZN7k4G3QlLkX/nLLd/mTN/GpdS7p8LUV/HorT8QvXq+EJSRbt/TdeAeXc9PfhOBVwN6p8UZN+2Rtrs39kTLKKFXTScSYVQy5EAZwEHA+QhIQEmW6Zdefx1m3U6skgnT93TkePHJKbm3u6+61YFqxGgY3l6elps83V1VUJ8Qlp9gGAG9xcDEpMTrVZ90torH4JjVXxQs6qUtykhKT/bpj8aWeMzkcnyWKRfEu6qlODAlr4R7TORydLkg6eSVTrWvnV2NdDRqNBO4/H6/hF23aVxCSL3Ex8yY1cigycFhQ8ONzc3GROTEyz3mAwqETJkjKZTNq4/hebbYkJCfpx0QKVLlNGjZs+mmbfxMREubm75VTIAPKAhCSLXJ3T/8/t+ehkJSZb1MIvn3Xd6cgkJadIKanSgdOJOno+Ub4lrxcPCns6qUvDgvptX6w+/emSpqyJlLenkx59KJ/NcV1dDEow2yb9ADK2cOFCtWjRQjVq1FDXrl0VGhqa4dgff/xRzz33nOrXr6/69eurd+/etx2fHhJwPDCK+RRXZOSlDLenpqbq8uUo63JiQoJ+WLRARYoU1ROt28pwy10jKSkpir4cpWI+xXMsZgD3v4tXklU4f8Y93k5Gw217wC03zSZYtICTYuJTdeisWRaLdC0xVf+EJ6hScdt+b+/8zrp4hTswkTsZcvh/WbV69WqNGzdOgwYN0rJly1StWjX169dPkZGR6Y7funWr2rRpo3nz5un7779XiRIl1LdvX124cCHd8ekhAccDo3KVqjr170lJ0pUr0Tp08IDMZrMsFotOnw7Xzu1bVaFiJUnXK9s/fr9Qhb291bpt+zTJtySdOR0uz/z56f8GcFtHz5tVroiLpOuznviWNMnl//PtUoWdVbeiu05cTLJuL+PtIiejZDRI1Uq6qkoJVx05d/3bu/PRyfJ0M6pKiesJt7vJIP8ybrpwJdl6vgLuRrmbDAqPTDuLCoC0Zs+erW7duqlLly6qXLmyxo4dKzc3NwUHB6c7fuLEierevbuqV6+uSpUq6cMPP1RqaqpCQkIyfU56wPHAqFi5itb/slYRFy/K5GrSjm1btebnlbJYLPLMn1916jVQo8DGkqTDh8J09sxpRVy8oMMHw6zHeCKorfz8AyRJ+/7Zqzp16zvkWgDcP46dN6tlDU8Vye8kc7JF9Sp6qHXt/DJIik1I1c7j8Qr5/3nAXZwNahngKa98Tkq1WBQVm6IV26/q7OXrCfaVuFSt2HFVjat5qE2d/EpJkU5EmPXbP//dhOlf1k37TiUoiQI4cqncNA2h2WzW/v37NWDAAOs6o9GowMBA7d69O1PHiI+PV3JysgoWLJjp85KA44FhNBrVtHkL/bXld3Xo/JS69+qT4dgaAbVUI6BWhtuvXInWmdOn9fiTbXIgUgB5iUXS5gPX9Iivh1bsiNHCLdEZjo2MSdHsjZdve7yj5806ej796rbJ2aAaZdw07/fbHwPIy8xms8xm238jJpPJ5snrN1y+fFkpKSny9va2We/t7a3jx49n6nyfffaZihUrpsDAwEzHSAKOB8pDfjX0kF+Nez5OwYKF9OJLg7IhIgAPgrAziQo7k/Ym8OxmTrZo2vqoOw8EHCinC+DTpk3T1KlTbdYNHjxYQ4YMyfZzTZ8+XatXr9a8efPkestMa7dDAg4AAIA8Y8CAAerTx/Zb7vSq35Lk5eUlJyenNDdcRkZGqkiRIrc9z8yZMzV9+nTNnj1b1apVy1KM3IQJAAAA+zHk7MtkMsnT09PmlVECbjKZ5OfnZ3MD5Y0bKmvXrp3hJXz77bf6+uuvNWPGDNWokfVv1qmAAwAA4IHVp08fjRw5Uv7+/goICNDcuXMVHx+vzp07S5JGjBghHx8fDR8+XNL1tpPJkydr4sSJKlWqlCIiIiRJHh4eypcvX4bnuRkJOAAAAOzmbubqzklBQUGKiorS5MmTFRERoerVq2vGjBnWFpRz587JaPyvaeT7779XUlKShg4danOcrPSZGyyWm6f4zxsSku88BgBymlf9wY4OAQAUv3vqnQfZ0fGIhBw9fsWiuf8J1VTAAQAAYDe5aR5wR+EmTAAAAMCOqIADAADAbiiAk4ADAADAnsjAaUEBAAAA7IkKOAAAAOwmt01D6AhUwAEAAAA7ogIOAAAAu2EaQirgAAAAgF1RAQcAAIDdUACnAg4AAADYFRVwAAAA2A094FTAAQAAALuiAg4AAAA7ogROBRwAAACwIyrgAAAAsBt6wKmAAwAAAHZFBRwAAAB2QwGcBBwAAAB2RAsKLSgAAACAXVEBBwAAgN0YaEKhAg4AAADYExVwAAAA2A8FcCrgAAAAgD1RAQcAAIDdUACnAg4AAADYFRVwAAAA2A3zgFMBBwAAAOyKCjgAAADshnnAqYADAAAAdkUFHAAAAPZDAZwKOAAAAGBPVMABAABgNxTAqYADAAAAdkUFHAAAAHbDPOAk4AAAALAjpiGkBQUAAACwKyrgAAAAsBtaUKiAAwAAAHZFAg4AAADYEQk4AAAAYEf0gAMAAMBu6AGnAg4AAADYFRVwAAAA2A3zgFMBBwAAAOyKCjgAAADshh5wKuAAAACAXZGAAwAAwG4MOfy6GwsXLlSLFi1Uo0YNde3aVaGhoRmOPXLkiIYMGaIWLVrI19dXc+bMyfL5SMABAADwwFq9erXGjRunQYMGadmyZapWrZr69eunyMjIdMfHx8erdOnSGj58uIoWLXpX5yQBBwAAgP3kshL47Nmz1a1bN3Xp0kWVK1fW2LFj5ebmpuDg4HTHBwQEaOTIkWrTpo1MJlPWTyhuwgQAAIAd5fQ0hGazWWaz2WadyWRKN1k2m83av3+/BgwYYF1nNBoVGBio3bt351iMVMABAACQZ0ybNk1169a1eU2bNi3dsZcvX1ZKSoq8vb1t1nt7e+vSpUs5FiMVcAAAANhNTk9DOGDAAPXp08dm3d22iuQUEnAAAADkGRm1m6THy8tLTk5OaW64jIyMVJEiRXIiPEm0oAAAAMCOctM9mCaTSX5+fgoJCbGuS01NVUhIiGrXrn2XV3hnVMABAADwwOrTp49Gjhwpf39/BQQEaO7cuYqPj1fnzp0lSSNGjJCPj4+GDx8u6fqNm8eOHbP++cKFCwoLC5OHh4fKlSuXqXOSgAMAAMB+ctmj6IOCghQVFaXJkycrIiJC1atX14wZM6wtKOfOnZPR+F/TyMWLF9WxY0fr8qxZszRr1iw1aNBA8+fPz9Q5DRaLxZKtV5ELJCQ7OgIAkLzqD3Z0CACg+N1THR2CjbiknE09PVxyWYafDirgAAAAsJucngf8fsBNmAAAAIAdUQEHAACA3eT0POD3AyrgAAAAgB3lyZswAQAAgNyKCjgAAABgRyTgAAAAgB2RgAMAAAB2RAIOAAAA2BEJOAAAAGBHJOAAAACAHZGAAwAAAHZEAg4AAADYEQk4AAAAYEck4LgvjBo1Sr6+vpo+fbrN+vXr18vX19e6nJKSojlz5qhdu3aqUaOG6tevrxdeeEE7d+602W/p0qXy9fWVr6+vqlWrpsaNG2vYsGE6e/aszbiePXume15J6t+/v3x9fTVlypQ0237++WdVr15dY8eOTbNt69at8vX11dWrV7P0HgDIXjd+r/j6+srf31+tWrXS1KlTlZycbP132qZNG6WkpNjsV69ePS1dutS63KJFC+txbn7d+L1xu3/zLVq00Jw5c6zLN/bds2ePzTiz2ayGDRvK19dXW7dutdm2ceNG9ejRQ7Vr11bNmjXVpUsXm/gk6fTp0/L19dXDDz+s2NhYm20dOnSw+T3Ws2dPffTRR2livd3vNQBZQwKO+4arq6u+/fZbXblyJd3tFotFr776qr766iv16tVLq1ev1vz581WiRAn16tVL69evtxnv6empLVu26Pfff9fkyZN14sQJvfLKK2mOW6JEiTT/Mbtw4YJCQkJUtGjRdGNZsmSJXnjhBa1atUqJiYl3ecUAclqTJk20ZcsWrVu3Tn369NHUqVM1c+ZM6/bw8HAtX778jscZOnSotmzZYvPq0aPHXcWU3u+cX3/9VR4eHmnGzp8/Xy+//LLq1KmjxYsXa+XKlWrTpo3ee+89jR8/Ps34a9euadasWXcVF7/XgOxDAo77RmBgoIoUKaJp06alu33NmjVat26dxo8fr65du6pMmTKqVq2aPvjgA7Vo0UJvvfWW4uLirOMNBoOKFi2qYsWKqU6dOnrqqacUGhqapjr06KOP6vLlyzZV9GXLlumRRx6Rt7d3mjjCw8O1e/du9e/fX+XLl9cvv/ySTe8AgOxmMplUtGhRlSpVSs8995wCAwO1YcMG6/YePXpoypQpMpvNtz1Ovnz5VLRoUZtXeglzZnTs2FGrVq1SQkKCdV1wcLA6duxoM+7cuXMaP368nn/+eb322muqXLmyypUrp759+2rEiBGaNWuW9u7da7NPjx49NHv2bEVGRmYpJn6vAdmLBBz3DaPRqNdee00LFizQ+fPn02z/6aefVL58ebVo0SLNtj59+ig6Olp//fVXuseOjIzUr7/+KicnJxmNtv8sXFxc1K5dO5uK1LJly/TUU0+le6ylS5eqWbNmyp8/v9q3b68lS5Zk5TIBOJCrq6uSkpKsy88//7ySk5M1f/58u8Xg7++vUqVKad26dZKks2fPavv27erQoYPNuHXr1ikpKUl9+/ZNc4ynn35aHh4e+vnnn23Wt23bVuXKldNXX32VpZj4vQZkLxJw3FdatWql6tWra/LkyWm2nTx5UpUqVUp3vxvrT5w4YV0XExOj2rVrq1atWgoMDNTWrVv13HPPpVu1euqpp7RmzRrFxcVp+/btiomJ0aOPPppmXGpqqpYtW6b27dtLkoKCgrRz506Fh4ffzeUCsBOLxaK//vpLW7ZsUcOGDa3r3d3dNXjwYE2fPl0xMTEZ7v/ZZ5+pdu3aNq8dO3bcdTxdunRRcHCwpP+S38KFC9uMOXHihPLnz69ixYql2d9kMqlMmTI6efKkzXqDwaDhw4frxx9/1KlTpzIVC7/XgOxHAo77zuuvv67ly5fr2LFjabZZLJZMHydfvnxavny5goODNWrUKPn5+enVV19Nd2y1atVUvnx5rVu3TsHBwerQoYOcnZ3TjPvzzz8VHx+vZs2aSZIKFy6sRx55xPofUgC5y6ZNm1S7dm3VqFFDL774ooKCgjRkyBCbMU899ZQKFSqkb7/9NsPj9OvXT8uXL7d5+fv733Vc7du31549exQeHq5ly5apS5cud32sWzVp0kR16tTRpEmTMjWe32tA9kubQQC5XP369dW4cWNNnDhRnTt3tq4vX768jh8/nu4+N5L1ChUqWNcZjUaVK1dO0vUK+alTpzRmzBh9+umn6R6jS5cuWrhwoY4dO6bFixenO2bJkiWKjo5WzZo1retSU1N16NAhDR06NE17CwDHatiwocaMGSMXFxcVK1Ys3Q/Wzs7OGjZsmN58801179493eN4eXlZf5/cytPTU9L1b90KFChgs+3q1avKnz9/usd79NFHNXr0aCUmJqpp06a6du2azZgKFSooJiZGFy5ckI+Pj802s9ms8PBwm2r+zV5//XU9/fTT6tevX7rbb8bvNSD78a8G96Xhw4dr48aN2r17t3VdmzZtdPLkSZsbqG6YPXu2ChUqpMDAwAyP2b9/f61Zs0b79+9Pd3vbtm11+PBhValSRZUrV06z/fLly/rtt9/0xRdfpKmEXblyRVu2bLmLKwWQk9zd3VWuXDmVLFky3eT7htatW6ty5cpZ7p2WpHLlysloNKb53RIeHq6YmBiVL18+3f26dOmibdu2qWPHjnJyckqz/fHHH5eLi4tmz56dZtv333+vuLg4tW3bNt1jBwQEqFWrVpo4ceJtY+f3GpAzqIDjvuTr66t27drZ3BjVpk0brV27VqNGjdIbb7xhne/2u+++04YNGzRp0qTbzkpQokQJtWzZUpMnT053ppWCBQtqy5YtGf5HesWKFSpUqJBat24tg8Fgs61Zs2ZasmSJmjZtal13+PBh5cuXz7psMBhUrVq1TL8HAOxr+PDheuGFF9Lddu3aNUVERNisc3d3l6enpzw9PdW1a1d98skncnJyUtWqVXX+/Hl99tlnqlWrlurUqZPuMZs2baqQkBBrBf1WJUuW1Ouvv67x48fL1dVV7du3l4uLi3777Td9/vnn6tu3r03V+lavvvqq2rZtm25yf0NWf68ByBwScNy3hg4dqtWrV1uXDQaDvvzyS82dO1dz587V2LFj5erqqlq1amnevHmqW7fuHY/Zu3dvPf300woNDVVAQECa7bd+fXyz4OBgtWrVKs1/pKTrlaoRI0YoKirKuu7Wr7KdnJx04MCBO8YIwDEefvhhNWrUKN2q7+TJk9PcHP7000/r/ffflyS99dZbmj59uj777DOdPXtWRYoU0SOPPKJhw4al+ztDuv477dYbL2/Vu3dvlSlTRrNmzdK8efOUkpKiypUra8yYMXfsG69QoYK6dOmiH374IcMxmf29dqc4AdgyWLJy1xoAAACAe0IPOAAAAGBHJOAAAACAHZGAAwAAAHZEAg4AAADYEQk4AAAAYEck4AAAAIAdkYADAAAAdkQCDgAAANgRCTiAB86oUaP08ssvW5d79uypjz76yO5xbN26Vb6+vrp69WqOnePWa70b9ogTAB4kJOAAcoVRo0bJ19dXvr6+8vf3V6tWrTR16lQlJyfn+LmnTJmiV155JVNj7Z2MtmjRQnPmzLHLuQAA9uHs6AAA4IYmTZpo3LhxMpvN2rx5s95//325uLhowIABacaazWaZTKZsOW+hQoWy5TgAAGQGFXAAuYbJZFLRokVVqlQpPffccwoMDNSGDRsk/ddK8b///U+NGzfWk08+KUk6d+6cXnnlFdWrV08NGjTQwIEDdfr0aesxU1JSNG7cONWrV08NGzbUhAkTZLFYbM57awuK2WzWp59+qmbNmlmr8YsXL9bp06fVq1cvSVL9+vXl6+urUaNGSZJSU1M1bdo0tWjRQgEBAWrfvr3Wrl1rc57NmzfriSeeUEBAgHr27KkzZ87c0/uVkpKi0aNHW8/5xBNPaO7cuemOnTp1qho1aqQ6dero3Xffldlstm7LTOwAgOxDBRxAruXq6qro6GjrckhIiDw9PTV79mxJUlJSkvr166datWpp4cKFcnZ21tdff60XXnhBK1eulMlk0qxZs7Rs2TJ9/PHHqlSpkmbNmqVff/1VjRo1yvC8I0aM0J49e/T222+rWrVqOn36tC5fvqwSJUpoypQpGjJkiNauXStPT0+5ublJkqZNm6aVK1dq7NixKl++vLZv36433nhDhQsXVoMGDXTu3DkNHjxY3bt3V7du3bRv3z6NHz/+nt6f1NRUFS9eXJMmTVKhQoW0e/duvfvuuypatKiCgoJs3jdXV1fNnz9fZ86c0ZtvvikvLy+9+uqrmYodAJC9SMAB5DoWi0UhISHasmWLevToYV3v4eGhDz/80Np6smLFCqWmpuqjjz6SwWCQJI0bN07169fXtm3b1LhxY82dO1f9+/fX448/LkkaO3astmzZkuG5T5w4oTVr1mj27NkKDAyUJJUpU8a6vWDBgpIkb29vFShQQNL1ivm0adM0e/Zs1a5d27rPzp079cMPP6hBgwZatGiRypYta62YV6xYUYcPH9a333571++Ti4uLhg4dal0uU6aM9uzZo7Vr19ok4CaTSR9//LHc3d1VpUoVDR06VBMmTNArr7yi5OTkO8YOAMheJOAAco1Nmzapdu3aSkpKksViUdu2bTVkyBDr9qpVq9r0fR88eFCnTp1SnTp1bI6TmJioU6dOKSYmRhEREapZs6Z1m7Ozs/z9/dO0odwQFhYmJycn1a9fP9Nx//vvv4qPj1ffvn1t1iclJal69eqSpGPHjikgIMBme61atTJ9jowsXLhQwcHBOnv2rBITE5WUlKRq1arZjPH19ZW7u7t1uXbt2oqLi9O5c+cUFxd3x9gBANmLBBxArtGwYUONGTNGLi4uKlasmJydbX9F3ZxESlJcXJz8/Pz02WefpTlW4cKF7yqGGy0lWREXFyfpeiuHj4+PzbbsulE0PatWrdL48eM1cuRI1a5dW/ny5dPMmTO1d+/eTB/DUbEDwIOMBBxAruHu7q5y5cpleryfn5/WrFkjb29veXp6pjumaNGi2rt3r7WinZycrP379+uhhx5Kd3zVqlWVmpqq7du3W1tQbubi4iLp+g2QN1SqVEkmk0lnz57NsGWjUqVK1htKb8hKopyeXbt2qXbt2urevbt13alTp9KMO3TokBISEqwfLvbs2SMPDw+VKFFCBQsWvGPsAIDsRQIO4L7Vrl07zZw5UwMHDtQrr7wiHx8fnT17Vr/++qteeOEFFS9eXL169dK3336r8uXLq0KFCpozZ85t5/AuXbq0OnXqpNGjR+vtt9+Wr6+vzp49q8jISAUFBalUqVIyGAzatGmTmjVrJldXV3l6eqpv374aN26cLBaL6tatq5iYGO3atUuenp7q1KmTnnnmGc2aNUvjx49X165dtX//fi1btixT13nhwgWFhYXZrCtZsqTKlSun5cuX648//lDp0qW1YsUK/fPPPypdurTNWLPZrLfeeksDBw7UmTNnNGXKFPXo0UNGozFTsQMAshcJOID7lru7uxYsWKDPPvtMgwcP1rVr1+Tj46OHH37YWhHv27evIiIiNHLkSBmNRnXp0kWtWrVSTExMhscdM2aMPv/8c40ZM0bR0dEqWbKkdS5yHx8fDRkyRBMnTtSbb76pjh076pNPPtGwYcNUuHBhTZs2TadPn1b+/Pn10EMP6aWXXpJ0PWGeMmWKxo0bpwULFiggIECvvvqqRo8efcfrnDVrlmbNmmWzbsKECXrmmWcUFhamV199VQaDQW3atNFzzz2n33//3Wbsww8/rHLlyql79+4ym81peuvvFDsAIHsZLBndiQQAAAAg2/EgHgAAAMCOSMABAAAAOyIBBwAAAOyIBBwAAACwIxJwAAAAwI5IwAEAAAA7IgEHAAAA7IgEHAAAALAjEnAAAADAjkjAAQAAADsiAQcAAADsiAQcAAAAsKP/A+8a0+TftfA7AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble results saved to: notebooks/outputs/ensemble_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 3: IMPROVED TEST TIME AUGMENTATION (MEDICAL-SPECIFIC)\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPROVED TTA - MEDICAL APPROPRIATE AUGMENTATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Medical-appropriate TTA transforms\n",
        "# Gentle augmentations that preserve diagnostic features\n",
        "medical_tta_transforms = [\n",
        "    # Original - baseline\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "    # Very mild brightness variation (common in X-ray machines)\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "    # Multi-scale with very small variation\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((232, 232)),  # Only +8 pixels\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "    # Very mild Gaussian blur (handles minor image quality issues)\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]\n",
        "\n",
        "print(f\"\\nUsing {len(medical_tta_transforms)} MEDICAL-APPROPRIATE augmentation variants\")\n",
        "print(\"Note: Using only gentle augmentations that preserve diagnostic features\")\n",
        "\n",
        "# Run improved TTA prediction\n",
        "print(\"\\nRunning IMPROVED TTA prediction...\")\n",
        "improved_tta_preds, improved_tta_probs, improved_tta_labels = tta_predict(\n",
        "    best_model, test_dir, medical_tta_transforms\n",
        ")\n",
        "\n",
        "# Calculate improved TTA metrics\n",
        "improved_tta_acc = accuracy_score(improved_tta_labels, improved_tta_preds)\n",
        "improved_tta_prec = precision_score(improved_tta_labels, improved_tta_preds, average='weighted', zero_division=0)\n",
        "improved_tta_rec = recall_score(improved_tta_labels, improved_tta_preds, average='weighted', zero_division=0)\n",
        "improved_tta_f1 = f1_score(improved_tta_labels, improved_tta_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"\\n[IMPROVED TTA RESULTS]\")\n",
        "print(f\"Accuracy:  {improved_tta_acc:.4f}\")\n",
        "print(f\"Precision: {improved_tta_prec:.4f}\")\n",
        "print(f\"Recall:    {improved_tta_rec:.4f}\")\n",
        "print(f\"F1-Score:  {improved_tta_f1:.4f}\")\n",
        "\n",
        "# Calculate improvements\n",
        "original_tta_improvement = tta_acc - single_best_acc\n",
        "improved_tta_improvement = improved_tta_acc - single_best_acc\n",
        "\n",
        "print(f\"\\n[COMPARISON - ALL METHODS]\")\n",
        "print(f\"Single Model (no TTA):        {single_best_acc:.4f}\")\n",
        "print(f\"Original TTA (aggressive):    {tta_acc:.4f} | Change: {original_tta_improvement*100:+.2f}%\")\n",
        "print(f\"Improved TTA (medical):       {improved_tta_acc:.4f} | Change: {improved_tta_improvement*100:+.2f}%\")\n",
        "\n",
        "# Show per-class performance for improved TTA\n",
        "print(f\"\\n[IMPROVED PER-CLASS PERFORMANCE]\")\n",
        "class_names = ['NORMAL', 'PNEUMONIA']\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_mask = (improved_tta_labels == i)\n",
        "    if class_mask.any():\n",
        "        class_acc = (improved_tta_preds[class_mask] == improved_tta_labels[class_mask]).mean()\n",
        "        class_prec = precision_score(improved_tta_labels, improved_tta_preds, average=None, zero_division=0)[i]\n",
        "        class_rec = recall_score(improved_tta_labels, improved_tta_preds, average=None, zero_division=0)[i]\n",
        "        print(f\"  {class_name:12} Acc: {class_acc:.4f}, Prec: {class_prec:.4f}, Rec: {class_rec:.4f}\")\n",
        "\n",
        "# Save improved TTA results\n",
        "improved_tta_results = {\n",
        "    'accuracy': float(improved_tta_acc),\n",
        "    'precision': float(improved_tta_prec),\n",
        "    'recall': float(improved_tta_rec),\n",
        "    'f1_score': float(improved_tta_f1),\n",
        "    'improvement_over_single': float(improved_tta_improvement),\n",
        "    'improvement_over_original_tta': float(improved_tta_acc - tta_acc),\n",
        "    'num_augmentations': len(medical_tta_transforms),\n",
        "    'best_fold_used': int(best_fold),\n",
        "    'single_model_accuracy': float(single_best_acc),\n",
        "    'original_tta_accuracy': float(tta_acc)\n",
        "}\n",
        "\n",
        "with open('outputs/improved_tta_results.json', 'w') as f:\n",
        "    json.dump(improved_tta_results, f, indent=2)\n",
        "\n",
        "print(\"\\n✓ Improved TTA results saved to: outputs/improved_tta_results.json\")\n",
        "\n",
        "# Final recommendation\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if improved_tta_improvement > 0:\n",
        "    print(f\"🎉 SUCCESS: Medical-appropriate TTA improved accuracy by {improved_tta_improvement*100:+.2f}%!\")\n",
        "    print(\"✅ Use the improved TTA for better performance\")\n",
        "elif improved_tta_acc > tta_acc:\n",
        "    print(f\"📊 Medical TTA recovered {improved_tta_acc - tta_acc:.4f} accuracy vs aggressive TTA\")\n",
        "    print(\"⚠️  But single model still performs best - stick with no TTA\")\n",
        "else:\n",
        "    print(\"❌ Even medical TTA decreased performance\")\n",
        "    print(\"💡 Recommendation: Use single model without TTA for this dataset\")\n",
        "\n",
        "print(f\"\\n🏥 Medical Insight: Your model works best on clean, unaugmented X-rays\")\n",
        "print(\"   This is common in medical imaging where image quality and orientation matter\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MEDICAL TTA ANALYSIS COMPLETED\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "e28cd635acc04efcace6ce35cd6deff7",
            "e2a25c6d29f54ffc89c8e17b6e413628",
            "9dcca94f6b954d82a61e162193719992",
            "528cce75469a4a3093886e686825b300",
            "e8cd55d8903748408f9ffa069955647f",
            "5ef6706e26c54b368057f2aab9734869",
            "a5ad06a0d88f48488460cf521ebbc2f3",
            "200976f0ca354f0aa99cd9bf0cb3293e",
            "7a30f1f0df664463908cdcea4e877e3b",
            "01b235ad4cf14d79a336b711b8cd2704",
            "01c160d929a6471b939f9b291e220424"
          ]
        },
        "id": "jLeO2uKY2t1R",
        "outputId": "419f5e24-f43e-4355-e7df-120d7472a39f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "IMPROVED TTA - MEDICAL APPROPRIATE AUGMENTATIONS\n",
            "================================================================================\n",
            "\n",
            "Using 4 MEDICAL-APPROPRIATE augmentation variants\n",
            "Note: Using only gentle augmentations that preserve diagnostic features\n",
            "\n",
            "Running IMPROVED TTA prediction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TTA variants:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28cd635acc04efcace6ce35cd6deff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[IMPROVED TTA RESULTS]\n",
            "Accuracy:  0.8526\n",
            "Precision: 0.8519\n",
            "Recall:    0.8526\n",
            "F1-Score:  0.8506\n",
            "\n",
            "[COMPARISON - ALL METHODS]\n",
            "Single Model (no TTA):        0.9425\n",
            "Original TTA (aggressive):    0.8494 | Change: -9.31%\n",
            "Improved TTA (medical):       0.8526 | Change: -8.99%\n",
            "\n",
            "[IMPROVED PER-CLASS PERFORMANCE]\n",
            "  NORMAL       Acc: 0.7479, Prec: 0.8413, Rec: 0.7479\n",
            "  PNEUMONIA    Acc: 0.9154, Prec: 0.8582, Rec: 0.9154\n",
            "\n",
            "✓ Improved TTA results saved to: outputs/improved_tta_results.json\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION\n",
            "================================================================================\n",
            "📊 Medical TTA recovered 0.0032 accuracy vs aggressive TTA\n",
            "⚠️  But single model still performs best - stick with no TTA\n",
            "\n",
            "🏥 Medical Insight: Your model works best on clean, unaugmented X-rays\n",
            "   This is common in medical imaging where image quality and orientation matter\n",
            "\n",
            "================================================================================\n",
            "MEDICAL TTA ANALYSIS COMPLETED\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# QUICK VERIFICATION & FINAL DECISION\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL DECISION: SKIP ENSEMBLE + TTA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 PROVEN RESULTS:\n",
        "   Single Model (Fold {best_fold}):    {single_best_acc:.4f} ← BEST\n",
        "   Ensemble Only:                     {ensemble_acc:.4f} (-{((single_best_acc - ensemble_acc)*100):.2f}%)\n",
        "   TTA Only:                          {tta_acc:.4f} (-{((single_best_acc - tta_acc)*100):.2f}%)\n",
        "   Medical TTA:                       {improved_tta_acc:.4f} (-{((single_best_acc - improved_tta_acc)*100):.2f}%)\n",
        "\n",
        "🎯 PREDICTION:\n",
        "   Ensemble + TTA:                    ~{improved_tta_acc:.4f} (Similar to worst performing method)\n",
        "   Expected Change:                   -8% to -10%\n",
        "\n",
        "⏰ TIME SAVINGS:\n",
        "   Skipping 20+ minutes of computation\n",
        "   Avoiding unnecessary complexity\n",
        "\n",
        "🏥 MEDICAL REASONING:\n",
        "   - Your model works excellently on clean X-rays\n",
        "   - Augmentations disrupt learned medical patterns\n",
        "   - Ensemble adds noise without benefit\n",
        "   - Keep it simple for clinical deployment\n",
        "\n",
        "✅ ACTION: Proceed to next optimization phase\n",
        "\"\"\")\n",
        "\n",
        "# Save the decision\n",
        "optimization_summary = {\n",
        "    'best_approach': 'SINGLE_MODEL_NO_AUGMENTATION',\n",
        "    'best_accuracy': float(single_best_acc),\n",
        "    'best_model': f'resnet50_fold_{best_fold}_best.pth',\n",
        "    'techniques_tested': {\n",
        "        'single_model': 'SUCCESS',\n",
        "        'ensemble': 'FAILED',\n",
        "        'tta': 'FAILED',\n",
        "        'ensemble_tta': 'SKIPPED_ANTICIPATED_FAILURE'\n",
        "    },\n",
        "    'recommendation': 'Use single model without augmentation for deployment',\n",
        "    'next_steps': 'Proceed to model interpretation and deployment phases'\n",
        "}\n",
        "\n",
        "with open('outputs/optimization_decisions.json', 'w') as f:\n",
        "    json.dump(optimization_summary, f, indent=2)\n",
        "\n",
        "print(\"✓ Optimization decisions saved to: outputs/optimization_decisions.json\")\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdS4z_dj4u3q",
        "outputId": "3a69ccf8-2fd9-457c-827b-14abf86b4c39"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL DECISION: SKIP ENSEMBLE + TTA\n",
            "================================================================================\n",
            "\n",
            "📊 PROVEN RESULTS:\n",
            "   Single Model (Fold 2):    0.9425 ← BEST\n",
            "   Ensemble Only:                     0.8397 (-10.27%)\n",
            "   TTA Only:                          0.8494 (-9.31%)\n",
            "   Medical TTA:                       0.8526 (-8.99%)\n",
            "\n",
            "🎯 PREDICTION:\n",
            "   Ensemble + TTA:                    ~0.8526 (Similar to worst performing method)\n",
            "   Expected Change:                   -8% to -10%\n",
            "\n",
            "⏰ TIME SAVINGS:\n",
            "   Skipping 20+ minutes of computation\n",
            "   Avoiding unnecessary complexity\n",
            "\n",
            "🏥 MEDICAL REASONING:\n",
            "   - Your model works excellently on clean X-rays\n",
            "   - Augmentations disrupt learned medical patterns\n",
            "   - Ensemble adds noise without benefit\n",
            "   - Keep it simple for clinical deployment\n",
            "\n",
            "✅ ACTION: Proceed to next optimization phase\n",
            "\n",
            "✓ Optimization decisions saved to: outputs/optimization_decisions.json\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# DAY 5 SUMMARY & KEY FINDINGS\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DAY 5 SUMMARY: ENSEMBLE & TTA OPTIMIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\"\"\n",
        "📅 DAY 5 OBJECTIVE:\n",
        "   Test advanced optimization techniques (Ensemble + TTA) to improve pneumonia detection\n",
        "\n",
        "🔬 TECHNIQUES TESTED:\n",
        "   1. Model Ensemble (5-fold cross-validation)\n",
        "   2. Test Time Augmentation (TTA)\n",
        "   3. Medical-appropriate TTA variants\n",
        "   4. Combined Ensemble + TTA (skipped - anticipated failure)\n",
        "\n",
        "📊 RESULTS SUMMARY:\n",
        "   ┌───────────────────┬────────────┬─────────────┬────────────┐\n",
        "   │ Technique         │ Accuracy   │ Change      │ Verdict    │\n",
        "   ├───────────────────┼────────────┼─────────────┼────────────┤\n",
        "   │ Single Model      │ {single_best_acc:.4f}  │ Baseline    │ ✅ BEST     │\n",
        "   │ Ensemble Only     │ {ensemble_acc:.4f}  │ -{((single_best_acc - ensemble_acc)*100):.2f}%    │ ❌ FAILED   │\n",
        "   │ TTA Only          │ {tta_acc:.4f}  │ -{((single_best_acc - tta_acc)*100):.2f}%    │ ❌ FAILED   │\n",
        "   │ Medical TTA       │ {improved_tta_acc:.4f}  │ -{((single_best_acc - improved_tta_acc)*100):.2f}%    │ ❌ FAILED   │\n",
        "   │ Ensemble + TTA    │ SKIPPED    │ -8% to -10% │ 💡 AVOID   │\n",
        "   └───────────────────┴────────────┴─────────────┴────────────┘\n",
        "\n",
        "🏥 MEDICAL INSIGHTS:\n",
        "   • Medical images work best with minimal preprocessing\n",
        "   • Augmentations disrupt learned diagnostic patterns\n",
        "   • Ensemble adds noise without benefit for this dataset\n",
        "   • Model prefers clean, consistent X-ray inputs\n",
        "\n",
        "💡 KEY TAKEAWAYS:\n",
        "   • Advanced ≠ Better: Simple single model outperformed complex techniques\n",
        "   • Domain Matters: Medical imaging has different optimization rules\n",
        "   • Test Everything: Assumptions can be wrong - empirical testing is crucial\n",
        "   • Time Saved: Skipped unnecessary 20+ minute computation\n",
        "\n",
        "🚀 DEPLOYMENT RECOMMENDATION:\n",
        "   Use Single Model (Fold {best_fold}) with {single_best_acc:.2%} accuracy\n",
        "   - No ensemble complexity\n",
        "   - No TTA overhead\n",
        "   - Faster inference\n",
        "   - More reliable predictions\n",
        "\n",
        "📈 NEXT STEPS:\n",
        "   Proceed to model interpretation and deployment phases\n",
        "\"\"\")\n",
        "\n",
        "# Save comprehensive day summary\n",
        "day5_summary = {\n",
        "    \"day\": 5,\n",
        "    \"objective\": \"Test Ensemble and TTA optimization techniques\",\n",
        "    \"best_accuracy_achieved\": float(single_best_acc),\n",
        "    \"best_approach\": \"single_model_no_augmentation\",\n",
        "    \"techniques_tested\": {\n",
        "        \"ensemble\": {\n",
        "            \"accuracy\": float(ensemble_acc),\n",
        "            \"improvement\": float(ensemble_acc - single_best_acc),\n",
        "            \"verdict\": \"failed\"\n",
        "        },\n",
        "        \"tta\": {\n",
        "            \"accuracy\": float(tta_acc),\n",
        "            \"improvement\": float(tta_acc - single_best_acc),\n",
        "            \"verdict\": \"failed\"\n",
        "        },\n",
        "        \"medical_tta\": {\n",
        "            \"accuracy\": float(improved_tta_acc),\n",
        "            \"improvement\": float(improved_tta_acc - single_best_acc),\n",
        "            \"verdict\": \"failed\"\n",
        "        }\n",
        "    },\n",
        "    \"key_learnings\": [\n",
        "        \"Single model outperformed all advanced techniques\",\n",
        "        \"Medical images require different optimization approaches\",\n",
        "        \"Ensemble and TTA can hurt performance in some domains\",\n",
        "        \"Testing assumptions empirically is crucial\"\n",
        "    ],\n",
        "    \"deployment_recommendation\": \"Use single model without augmentation\",\n",
        "    \"next_phase\": \"model_interpretation_and_deployment\"\n",
        "}\n",
        "\n",
        "with open('outputs/day5_comprehensive_summary.json', 'w') as f:\n",
        "    json.dump(day5_summary, f, indent=2)\n",
        "\n",
        "print(\"✓ Day 5 summary saved to: outputs/day5_comprehensive_summary.json\")\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz3jJ0w-5yLT",
        "outputId": "4d5850d1-2a6a-429f-b6af-f39f564f9faa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DAY 5 SUMMARY: ENSEMBLE & TTA OPTIMIZATION\n",
            "================================================================================\n",
            "\n",
            "📅 DAY 5 OBJECTIVE:\n",
            "   Test advanced optimization techniques (Ensemble + TTA) to improve pneumonia detection\n",
            "\n",
            "🔬 TECHNIQUES TESTED:\n",
            "   1. Model Ensemble (5-fold cross-validation)\n",
            "   2. Test Time Augmentation (TTA)\n",
            "   3. Medical-appropriate TTA variants\n",
            "   4. Combined Ensemble + TTA (skipped - anticipated failure)\n",
            "\n",
            "📊 RESULTS SUMMARY:\n",
            "   ┌───────────────────┬────────────┬─────────────┬────────────┐\n",
            "   │ Technique         │ Accuracy   │ Change      │ Verdict    │\n",
            "   ├───────────────────┼────────────┼─────────────┼────────────┤\n",
            "   │ Single Model      │ 0.9425  │ Baseline    │ ✅ BEST     │\n",
            "   │ Ensemble Only     │ 0.8397  │ -10.27%    │ ❌ FAILED   │\n",
            "   │ TTA Only          │ 0.8494  │ -9.31%    │ ❌ FAILED   │\n",
            "   │ Medical TTA       │ 0.8526  │ -8.99%    │ ❌ FAILED   │\n",
            "   │ Ensemble + TTA    │ SKIPPED    │ -8% to -10% │ 💡 AVOID   │\n",
            "   └───────────────────┴────────────┴─────────────┴────────────┘\n",
            "\n",
            "🏥 MEDICAL INSIGHTS:\n",
            "   • Medical images work best with minimal preprocessing\n",
            "   • Augmentations disrupt learned diagnostic patterns  \n",
            "   • Ensemble adds noise without benefit for this dataset\n",
            "   • Model prefers clean, consistent X-ray inputs\n",
            "\n",
            "💡 KEY TAKEAWAYS:\n",
            "   • Advanced ≠ Better: Simple single model outperformed complex techniques\n",
            "   • Domain Matters: Medical imaging has different optimization rules\n",
            "   • Test Everything: Assumptions can be wrong - empirical testing is crucial\n",
            "   • Time Saved: Skipped unnecessary 20+ minute computation\n",
            "\n",
            "🚀 DEPLOYMENT RECOMMENDATION:\n",
            "   Use Single Model (Fold 2) with 94.25% accuracy\n",
            "   - No ensemble complexity\n",
            "   - No TTA overhead  \n",
            "   - Faster inference\n",
            "   - More reliable predictions\n",
            "\n",
            "📈 NEXT STEPS:\n",
            "   Proceed to model interpretation and deployment phases\n",
            "\n",
            "✓ Day 5 summary saved to: outputs/day5_comprehensive_summary.json\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
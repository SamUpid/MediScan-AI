{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s7U-zWL9ChZG",
        "outputId": "5c1341ea-5165-4641-a564-82b5dbc09f6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIMPORTANT FIX: Test on REAL test set (624 images models have NEVER seen)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#================================================================================\n",
        "# DAY 5.5: CORRECT ENSEMBLE & TTA TESTING ON REAL TEST SET - COLAB OPTIMIZED\n",
        "#================================================================================\n",
        "\"\"\"\n",
        "IMPORTANT FIX: Test on REAL test set (624 images models have NEVER seen)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# SETUP & DEPENDENCIES - COLAB OPTIMIZED\n",
        "#================================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DAY 5.5: CORRECT ENSEMBLE & TTA TESTING - COLAB VERSION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Install required packages\n",
        "!pip install seaborn tqdm --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                              f1_score, confusion_matrix, classification_report)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Setup device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Define model architecture (MUST BE SAME AS TRAINING)\n",
        "def build_model(num_classes=2, dropout_rate=0.5):\n",
        "    \"\"\"Build ResNet50 model - MUST match training architecture\"\"\"\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Class names (hardcoded since we might not have dataset_info.json)\n",
        "class_names = ['NORMAL', 'PNEUMONIA']\n",
        "num_classes = 2\n",
        "\n",
        "print(\"Dependencies loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq9-hFIFIY8Q",
        "outputId": "a779b490-92d3-4efb-a01a-9d7745d307d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DAY 5.5: CORRECT ENSEMBLE & TTA TESTING - COLAB VERSION\n",
            "================================================================================\n",
            "Device: cuda\n",
            "Dependencies loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# UPLOAD LOCAL FILES TO COLAB\n",
        "#================================================================================\n",
        "\n",
        "print(\"UPLOAD YOUR LOCAL FILES TO COLAB\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Create necessary directories in Colab\n",
        "Path('/content/data').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/models').mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/notebooks/models').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"STEP 1: Upload your test.zip file\")\n",
        "print(\"Please upload test.zip that contains test images\")\n",
        "print(\"\")\n",
        "\n",
        "uploaded_data = files.upload()\n",
        "\n",
        "# Process uploaded data files\n",
        "for filename in uploaded_data.keys():\n",
        "    print(f\"Processing: {filename}\")\n",
        "\n",
        "    if filename.endswith('.zip'):\n",
        "        print(\"Extracting zip file...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/data/')\n",
        "        print(\"Extraction complete!\")\n",
        "        break  # Only process first zip file\n",
        "\n",
        "print(\"\")\n",
        "print(\"STEP 2: Upload your model files (.pth files)\")\n",
        "print(\"Please upload at least 3 model files for ensemble\")\n",
        "print(\"\")\n",
        "\n",
        "uploaded_models = files.upload()\n",
        "\n",
        "# Move model files to correct location\n",
        "for filename in uploaded_models.keys():\n",
        "    if filename.endswith('.pth'):\n",
        "        # Copy to both locations for flexibility\n",
        "        os.rename(filename, f'/content/models/{filename}')\n",
        "        os.system(f'cp /content/models/{filename} /content/notebooks/models/{filename}')\n",
        "        print(f\"Model saved: {filename}\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"VERIFICATION:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Check what was uploaded\n",
        "print(\"Data directory contents:\")\n",
        "data_path = Path('/content/data')\n",
        "if data_path.exists():\n",
        "    for item in data_path.rglob('*'):\n",
        "        if item.is_dir():\n",
        "            print(f\"  - {item}\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"Models directory contents:\")\n",
        "models_path = Path('/content/models')\n",
        "if models_path.exists():\n",
        "    for item in models_path.glob('*.pth'):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"UPLOAD COMPLETE!\")\n",
        "print(\"Now running Day 5.5 testing code...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "a_zfOzOVIf8a",
        "outputId": "e3cd2064-66b2-4f42-ba52-f017179ed5f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UPLOAD YOUR LOCAL FILES TO COLAB\n",
            "==================================================\n",
            "STEP 1: Upload your test.zip file\n",
            "Please upload test.zip that contains test images\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e3f12dbc-fb4d-4793-8200-93a46085f641\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e3f12dbc-fb4d-4793-8200-93a46085f641\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.zip to test (1).zip\n",
            "Processing: test (1).zip\n",
            "Extracting zip file...\n",
            "Extraction complete!\n",
            "\n",
            "STEP 2: Upload your model files (.pth files)\n",
            "Please upload at least 3 model files for ensemble\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8900e512-381a-4168-8119-306c316da3d6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8900e512-381a-4168-8119-306c316da3d6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_2_best.pth to resnet50_fold_2_best.pth\n",
            "Model saved: resnet50_fold_2_best.pth\n",
            "\n",
            "VERIFICATION:\n",
            "==============================\n",
            "Data directory contents:\n",
            "  - /content/data/test\n",
            "  - /content/data/test/PNEUMONIA\n",
            "  - /content/data/test/NORMAL\n",
            "\n",
            "Models directory contents:\n",
            "  - /content/models/resnet50_fold_2_best.pth\n",
            "\n",
            "UPLOAD COMPLETE!\n",
            "Now running Day 5.5 testing code...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 1 CONTINUED: SETUP TEST DATA\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SETUP TEST DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find test directory - check multiple possible locations\n",
        "test_dirs = [\n",
        "    Path('/content/data/test'),\n",
        "    Path('/content/data/chest_xray/test'),\n",
        "    Path('/content/data/chest_xray/chest_xray/test'),\n",
        "    Path('/content/test')\n",
        "]\n",
        "\n",
        "test_dir = None\n",
        "for test_path in test_dirs:\n",
        "    if test_path.exists():\n",
        "        test_dir = test_path\n",
        "        break\n",
        "\n",
        "if test_dir is None:\n",
        "    print(\"ERROR: Test directory not found!\")\n",
        "    print(\"Available directories in /content/data/:\")\n",
        "    data_path = Path('/content/data')\n",
        "    if data_path.exists():\n",
        "        for item in data_path.rglob('*'):\n",
        "            if item.is_dir():\n",
        "                print(f\"  - {item}\")\n",
        "    raise FileNotFoundError(\"Please check if test.zip was extracted correctly\")\n",
        "\n",
        "print(f\"Test directory: {test_dir}\")\n",
        "\n",
        "# Count test images\n",
        "normal_count = len(list(test_dir.glob('NORMAL/*.jpeg')))\n",
        "pneumonia_count = len(list(test_dir.glob('PNEUMONIA/*.jpeg')))\n",
        "total_test = normal_count + pneumonia_count\n",
        "\n",
        "print(f\"Test data found:\")\n",
        "print(f\"  - NORMAL: {normal_count} images\")\n",
        "print(f\"  - PNEUMONIA: {pneumonia_count} images\")\n",
        "print(f\"  - TOTAL: {total_test} images\")\n",
        "\n",
        "# Test transform\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = ImageFolder(root=str(test_dir), transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Test dataset loaded successfully\")\n",
        "\n",
        "# We don't have Day 4 baseline, so we'll calculate it\n",
        "print(\"Note: Calculating baseline from single model (no Day 4 results available)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOY3BpkdIjaS",
        "outputId": "0d77073f-8ef0-4efb-d20c-1dd524ed0ec1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SETUP TEST DATA\n",
            "================================================================================\n",
            "Test directory: /content/data/test\n",
            "Test data found:\n",
            "  - NORMAL: 234 images\n",
            "  - PNEUMONIA: 390 images\n",
            "  - TOTAL: 624 images\n",
            "Test dataset loaded successfully\n",
            "Note: Calculating baseline from single model (no Day 4 results available)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# UPLOAD ADDITIONAL MODELS FOR PROPER ENSEMBLE\n",
        "#================================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"UPLOAD ADDITIONAL MODELS FOR PROPER ENSEMBLE TESTING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Please upload 2 more model files:\")\n",
        "print(\"1. resnet50_fold_1_best.pth\")\n",
        "print(\"2. resnet50_fold_3_best.pth\")\n",
        "print(\"\")\n",
        "\n",
        "# Upload additional models\n",
        "additional_models = files.upload()\n",
        "\n",
        "# Process uploaded models\n",
        "for filename in additional_models.keys():\n",
        "    if filename.endswith('.pth'):\n",
        "        # Copy to both locations\n",
        "        os.rename(filename, f'/content/models/{filename}')\n",
        "        os.system(f'cp /content/models/{filename} /content/notebooks/models/{filename}')\n",
        "        print(f\"✓ Uploaded: {filename}\")\n",
        "\n",
        "# Verify current model count\n",
        "models_count = len([f for f in os.listdir('/content/models') if f.endswith('.pth')])\n",
        "print(f\"\\n✓ Total models now: {models_count}\")\n",
        "print(\"Available models:\")\n",
        "for model_file in sorted(os.listdir('/content/models')):\n",
        "    if model_file.endswith('.pth'):\n",
        "        print(f\"  - {model_file}\")\n",
        "\n",
        "print(\"1. CELL 2: Load All 5 Models\")\n",
        "print(\"2. CELL 3: Ensemble Prediction\")\n",
        "print(\"3. Continue with remaining cells\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "tx1hj0CaV7l0",
        "outputId": "3ae44744-29f1-4d9e-b902-48081f8e5acd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "UPLOAD ADDITIONAL MODELS FOR PROPER ENSEMBLE TESTING\n",
            "================================================================================\n",
            "Please upload 2 more model files:\n",
            "1. resnet50_fold_1_best.pth\n",
            "2. resnet50_fold_3_best.pth\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1efe58f7-824c-4fe2-b219-28c51e1103f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1efe58f7-824c-4fe2-b219-28c51e1103f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_1_best.pth to resnet50_fold_1_best.pth\n",
            "✓ Uploaded: resnet50_fold_1_best.pth\n",
            "\n",
            "✓ Total models now: 2\n",
            "Available models:\n",
            "  - resnet50_fold_1_best.pth\n",
            "  - resnet50_fold_2_best.pth\n",
            "1. CELL 2: Load All 5 Models\n",
            "2. CELL 3: Ensemble Prediction\n",
            "3. Continue with remaining cells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# UPLOAD ADDITIONAL MODELS FOR PROPER ENSEMBLE\n",
        "#================================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"UPLOAD ADDITIONAL MODELS FOR PROPER ENSEMBLE TESTING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Please upload 2 more model files:\")\n",
        "print(\"1. resnet50_fold_1_best.pth\")\n",
        "print(\"2. resnet50_fold_3_best.pth\")\n",
        "print(\"\")\n",
        "\n",
        "# Upload additional models\n",
        "additional_models = files.upload()\n",
        "\n",
        "# Process uploaded models\n",
        "for filename in additional_models.keys():\n",
        "    if filename.endswith('.pth'):\n",
        "        # Copy to both locations\n",
        "        os.rename(filename, f'/content/models/{filename}')\n",
        "        os.system(f'cp /content/models/{filename} /content/notebooks/models/{filename}')\n",
        "        print(f\"✓ Uploaded: {filename}\")\n",
        "\n",
        "# Verify current model count\n",
        "models_count = len([f for f in os.listdir('/content/models') if f.endswith('.pth')])\n",
        "print(f\"\\n✓ Total models now: {models_count}\")\n",
        "print(\"Available models:\")\n",
        "for model_file in sorted(os.listdir('/content/models')):\n",
        "    if model_file.endswith('.pth'):\n",
        "        print(f\"  - {model_file}\")\n",
        "\n",
        "print(\"1. CELL 2: Load All 5 Models\")\n",
        "print(\"2. CELL 3: Ensemble Prediction\")\n",
        "print(\"3. Continue with remaining cells\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "LjupMpB9YY2a",
        "outputId": "c897733b-3520-4762-f6c1-f8fd902e35aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "UPLOAD ADDITIONAL MODELS FOR PROPER ENSEMBLE TESTING\n",
            "================================================================================\n",
            "Please upload 2 more model files:\n",
            "1. resnet50_fold_1_best.pth\n",
            "2. resnet50_fold_3_best.pth\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-874aa028-7da2-4422-b997-23c8f86e112d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-874aa028-7da2-4422-b997-23c8f86e112d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resnet50_fold_3_best.pth to resnet50_fold_3_best.pth\n",
            "✓ Uploaded: resnet50_fold_3_best.pth\n",
            "\n",
            "✓ Total models now: 3\n",
            "Available models:\n",
            "  - resnet50_fold_1_best.pth\n",
            "  - resnet50_fold_2_best.pth\n",
            "  - resnet50_fold_3_best.pth\n",
            "1. CELL 2: Load All 5 Models\n",
            "2. CELL 3: Ensemble Prediction\n",
            "3. Continue with remaining cells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 2: LOAD ALL 5 MODELS & ESTABLISH BASELINE\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING ALL 5 FOLD MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def build_model(num_classes=2, dropout_rate=0.5):\n",
        "    \"\"\"Build ResNet50 model\"\"\"\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model.to(device)\n",
        "\n",
        "# Load all 5 models with flexible paths\n",
        "models_list = []\n",
        "model_paths = []\n",
        "\n",
        "# Check multiple possible model locations\n",
        "possible_model_dirs = [\n",
        "    Path('/content/models'),\n",
        "    Path('/content/notebooks/models'),\n",
        "    Path('/content')\n",
        "]\n",
        "\n",
        "for fold in range(1, 6):\n",
        "    model_found = False\n",
        "    model_filename = f'resnet50_fold_{fold}_best.pth'\n",
        "\n",
        "    for model_dir in possible_model_dirs:\n",
        "        checkpoint_path = model_dir / model_filename\n",
        "        if checkpoint_path.exists():\n",
        "            try:\n",
        "                print(f\"Loading {model_filename} from {checkpoint_path}...\")\n",
        "                checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "                model = build_model(num_classes=num_classes, dropout_rate=0.5)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                model.eval()\n",
        "                models_list.append(model)\n",
        "                model_paths.append(str(checkpoint_path))\n",
        "\n",
        "                # Get validation accuracy from checkpoint\n",
        "                val_acc = checkpoint.get('val_acc', checkpoint.get('best_acc', 'Unknown'))\n",
        "                print(f\"  ✓ Loaded Fold {fold} (Val Acc: {val_acc})\")\n",
        "                model_found = True\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Failed to load {model_filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "    if not model_found:\n",
        "        print(f\"   Model for fold {fold} not found in any location\")\n",
        "\n",
        "if not models_list:\n",
        "    raise FileNotFoundError(\"No models could be loaded! Please check model upload.\")\n",
        "\n",
        "print(f\"\\n✓ Successfully loaded {len(models_list)} models\")\n",
        "\n",
        "# Calculate baseline from single best model (since we don't have Day 4 results)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CALCULATING BASELINE PERFORMANCE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def single_model_predict(model, dataloader):\n",
        "    \"\"\"Get predictions from single model for baseline\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc='Baseline prediction'):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "# Use the first model as baseline (or find the best one if we have validation accuracies)\n",
        "print(\"Testing single model performance on real test set...\")\n",
        "baseline_preds, baseline_labels = single_model_predict(models_list[0], test_loader)\n",
        "\n",
        "baseline_accuracy = accuracy_score(baseline_labels, baseline_preds)\n",
        "baseline_precision = precision_score(baseline_labels, baseline_preds, average='weighted', zero_division=0)\n",
        "baseline_recall = recall_score(baseline_labels, baseline_preds, average='weighted', zero_division=0)\n",
        "baseline_f1 = f1_score(baseline_labels, baseline_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"\\n[BASELINE RESULTS - SINGLE MODEL ON REAL TEST SET]\")\n",
        "print(f\"Accuracy:  {baseline_accuracy:.4f}\")\n",
        "print(f\"Precision: {baseline_precision:.4f}\")\n",
        "print(f\"Recall:    {baseline_recall:.4f}\")\n",
        "print(f\"F1-Score:  {baseline_f1:.4f}\")\n",
        "\n",
        "# Save baseline for comparison\n",
        "baseline_results = {\n",
        "    'test_accuracy': float(baseline_accuracy),\n",
        "    'test_precision': float(baseline_precision),\n",
        "    'test_recall': float(baseline_recall),\n",
        "    'test_f1': float(baseline_f1),\n",
        "    'test_set_size': total_test,\n",
        "    'model_used': 'resnet50_fold_1_best.pth'\n",
        "}\n",
        "\n",
        "# Create outputs directory\n",
        "outputs_dir = Path('/content/notebooks/outputs')\n",
        "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(outputs_dir / 'day5_5_baseline.json', 'w') as f:\n",
        "    json.dump(baseline_results, f, indent=2)\n",
        "\n",
        "print(f\"✓ Baseline saved to: {outputs_dir / 'day5_5_baseline.json'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM9HFESQUYmo",
        "outputId": "390376a8-64af-464b-f691-f6707a03b677"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING ALL 5 FOLD MODELS\n",
            "================================================================================\n",
            "Loading resnet50_fold_1_best.pth from /content/models/resnet50_fold_1_best.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Loaded Fold 1 (Val Acc: 0.9425287356321839)\n",
            "Loading resnet50_fold_2_best.pth from /content/models/resnet50_fold_2_best.pth...\n",
            "  ✓ Loaded Fold 2 (Val Acc: 0.9549376797698945)\n",
            "Loading resnet50_fold_3_best.pth from /content/models/resnet50_fold_3_best.pth...\n",
            "  ✓ Loaded Fold 3 (Val Acc: 0.9376797698945349)\n",
            "   Model for fold 4 not found in any location\n",
            "   Model for fold 5 not found in any location\n",
            "\n",
            "✓ Successfully loaded 3 models\n",
            "\n",
            "==================================================\n",
            "CALCULATING BASELINE PERFORMANCE\n",
            "==================================================\n",
            "Testing single model performance on real test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Baseline prediction: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[BASELINE RESULTS - SINGLE MODEL ON REAL TEST SET]\n",
            "Accuracy:  0.8429\n",
            "Precision: 0.8418\n",
            "Recall:    0.8429\n",
            "F1-Score:  0.8410\n",
            "✓ Baseline saved to: /content/notebooks/outputs/day5_5_baseline.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 3: TEST METHOD 1 - ENSEMBLE (5 MODELS)\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"METHOD 1: ENSEMBLE PREDICTION ON REAL TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def ensemble_predict(models, dataloader):\n",
        "    \"\"\"Average predictions from multiple models\"\"\"\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc='Ensemble predicting'):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Get predictions from all models\n",
        "            batch_probs = []\n",
        "            for model in models:\n",
        "                outputs = model(images)\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                batch_probs.append(probs.cpu().numpy())\n",
        "\n",
        "            # Average probabilities\n",
        "            avg_probs = np.mean(batch_probs, axis=0)\n",
        "            all_probs.extend(avg_probs)\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "    predictions = np.argmax(all_probs, axis=1)\n",
        "\n",
        "    return predictions, all_probs, all_labels\n",
        "\n",
        "# Run ensemble prediction\n",
        "print(f\"\\nRunning ensemble prediction with {len(models_list)} models...\")\n",
        "ensemble_preds, ensemble_probs, true_labels = ensemble_predict(models_list, test_loader)\n",
        "\n",
        "# Calculate metrics\n",
        "ensemble_acc = accuracy_score(true_labels, ensemble_preds)\n",
        "ensemble_prec = precision_score(true_labels, ensemble_preds, average='weighted', zero_division=0)\n",
        "ensemble_rec = recall_score(true_labels, ensemble_preds, average='weighted', zero_division=0)\n",
        "ensemble_f1 = f1_score(true_labels, ensemble_preds, average='weighted', zero_division=0)\n",
        "ensemble_cm = confusion_matrix(true_labels, ensemble_preds)\n",
        "\n",
        "print(f\"\\n[ENSEMBLE RESULTS]\")\n",
        "print(f\"Accuracy:  {ensemble_acc:.4f}\")\n",
        "print(f\"Precision: {ensemble_prec:.4f}\")\n",
        "print(f\"Recall:    {ensemble_rec:.4f}\")\n",
        "print(f\"F1-Score:  {ensemble_f1:.4f}\")\n",
        "\n",
        "improvement = ensemble_acc - baseline_accuracy\n",
        "print(f\"\\n[COMPARISON]\")\n",
        "print(f\"Baseline (Single Model): {baseline_accuracy:.4f}\")\n",
        "print(f\"Ensemble ({len(models_list)} Models):  {ensemble_acc:.4f}\")\n",
        "print(f\"Change:                  {improvement:+.4f} ({improvement*100:+.2f}%)\")\n",
        "\n",
        "if improvement > 0:\n",
        "    print(f\"\\nSUCCESS: Ensemble improved accuracy by {improvement*100:.2f}%\")\n",
        "else:\n",
        "    print(f\"\\nNO IMPROVEMENT: Ensemble decreased accuracy by {abs(improvement)*100:.2f}%\")\n",
        "\n",
        "# Per-class performance\n",
        "print(f\"\\n[PER-CLASS PERFORMANCE]\")\n",
        "class_report = classification_report(true_labels, ensemble_preds,\n",
        "                                     target_names=class_names, output_dict=True)\n",
        "for cls in class_names:\n",
        "    metrics = class_report[cls]\n",
        "    print(f\"  {cls:12} Prec: {metrics['precision']:.3f}, \"\n",
        "          f\"Rec: {metrics['recall']:.3f}, F1: {metrics['f1-score']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDKCcshTUjZB",
        "outputId": "a37e8dce-24b6-4e07-8340-16dac055d5a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "METHOD 1: ENSEMBLE PREDICTION ON REAL TEST SET\n",
            "================================================================================\n",
            "\n",
            "Running ensemble prediction with 3 models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ensemble predicting: 100%|██████████| 20/20 [00:10<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ENSEMBLE RESULTS]\n",
            "Accuracy:  0.8365\n",
            "Precision: 0.8360\n",
            "Recall:    0.8365\n",
            "F1-Score:  0.8335\n",
            "\n",
            "[COMPARISON]\n",
            "Baseline (Single Model): 0.8429\n",
            "Ensemble (3 Models):  0.8365\n",
            "Change:                  -0.0064 (-0.64%)\n",
            "\n",
            "NO IMPROVEMENT: Ensemble decreased accuracy by 0.64%\n",
            "\n",
            "[PER-CLASS PERFORMANCE]\n",
            "  NORMAL       Prec: 0.830, Rec: 0.709, F1: 0.765\n",
            "  PNEUMONIA    Prec: 0.840, Rec: 0.913, F1: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 4: TEST METHOD 2 - TEST TIME AUGMENTATION (TTA)\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"METHOD 2: TEST TIME AUGMENTATION (TTA)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use medical-appropriate TTA transforms\n",
        "tta_transforms = [\n",
        "    # Original\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    # Horizontal flip (medically safe)\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    # Very mild brightness (simulates X-ray machine variations)\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]\n",
        "\n",
        "print(f\"Using {len(tta_transforms)} medical-appropriate augmentation variants\")\n",
        "\n",
        "def tta_predict(model, test_dir, transforms_list):\n",
        "    \"\"\"Predict with test time augmentation\"\"\"\n",
        "    all_predictions = []\n",
        "\n",
        "    for transform in tqdm(transforms_list, desc='TTA variants'):\n",
        "        dataset = ImageFolder(root=str(test_dir), transform=transform)\n",
        "        loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for images, _ in loader:\n",
        "                images = images.to(device)\n",
        "                outputs = model(images)\n",
        "                batch_probs = torch.softmax(outputs, dim=1)\n",
        "                probs.extend(batch_probs.cpu().numpy())\n",
        "\n",
        "        all_predictions.append(np.array(probs))\n",
        "\n",
        "    # Average predictions\n",
        "    avg_probs = np.mean(all_predictions, axis=0)\n",
        "    predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "    # Get true labels\n",
        "    dataset = ImageFolder(root=str(test_dir), transform=transforms_list[0])\n",
        "    labels = np.array([label for _, label in dataset])\n",
        "\n",
        "    return predictions, avg_probs, labels\n",
        "\n",
        "# Use the best single model (Fold 2)\n",
        "best_model = models_list[1]  # Fold 2 had 85.26% previously\n",
        "print(f\"Using best single model: Fold 2\")\n",
        "print(\"Running TTA prediction...\")\n",
        "\n",
        "tta_preds, tta_probs, tta_labels = tta_predict(best_model, test_dir, tta_transforms)\n",
        "\n",
        "# Calculate TTA metrics\n",
        "tta_acc = accuracy_score(tta_labels, tta_preds)\n",
        "tta_prec = precision_score(tta_labels, tta_preds, average='weighted', zero_division=0)\n",
        "tta_rec = recall_score(tta_labels, tta_preds, average='weighted', zero_division=0)\n",
        "tta_f1 = f1_score(tta_labels, tta_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"\\n[TTA RESULTS]\")\n",
        "print(f\"Accuracy:  {tta_acc:.4f}\")\n",
        "print(f\"Precision: {tta_prec:.4f}\")\n",
        "print(f\"Recall:    {tta_rec:.4f}\")\n",
        "print(f\"F1-Score:  {tta_f1:.4f}\")\n",
        "\n",
        "tta_improvement = tta_acc - 0.8526  # Compare to Fold 2's previous performance\n",
        "print(f\"\\n[COMPARISON]\")\n",
        "print(f\"Single Model (Fold 2): {0.8526:.4f}\")\n",
        "print(f\"With TTA:              {tta_acc:.4f}\")\n",
        "print(f\"Change:                {tta_improvement:+.4f} ({tta_improvement*100:+.2f}%)\")\n",
        "\n",
        "if tta_improvement > 0:\n",
        "    print(f\"\\nSUCCESS: TTA improved accuracy by {tta_improvement*100:.2f}%\")\n",
        "else:\n",
        "    print(f\"\\nNO IMPROVEMENT: TTA decreased accuracy by {abs(tta_improvement)*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b268KHTObi7O",
        "outputId": "93128da5-f55c-49c7-fccb-17514577e8c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "METHOD 2: TEST TIME AUGMENTATION (TTA)\n",
            "================================================================================\n",
            "Using 3 medical-appropriate augmentation variants\n",
            "Using best single model: Fold 2\n",
            "Running TTA prediction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA variants: 100%|██████████| 3/3 [00:27<00:00,  9.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TTA RESULTS]\n",
            "Accuracy:  0.8494\n",
            "Precision: 0.8486\n",
            "Recall:    0.8494\n",
            "F1-Score:  0.8474\n",
            "\n",
            "[COMPARISON]\n",
            "Single Model (Fold 2): 0.8526\n",
            "With TTA:              0.8494\n",
            "Change:                -0.0032 (-0.32%)\n",
            "\n",
            "NO IMPROVEMENT: TTA decreased accuracy by 0.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# CELL 5: FINAL SUMMARY & RECOMMENDATIONS\n",
        "#================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DAY 5.5 FINAL SUMMARY & RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 REAL TEST SET PERFORMANCE (624 images):\n",
        "\n",
        "SINGLE MODELS:\n",
        "  Fold 1: 84.29% (Val: 94.25%) ← OVERFIT: -9.96%\n",
        "  Fold 2: 85.26% (Val: 95.49%) ← OVERFIT: -10.23%  BEST\n",
        "  Fold 3: ~84.00% (Val: 93.77%) ← OVERFIT: ~-9.77%\n",
        "\n",
        "ADVANCED TECHNIQUES:\n",
        "  Ensemble (3 models):   83.65%  ← -1.61% vs best single\n",
        "  TTA (3 variants):      84.94%  ← -0.32% vs best single\n",
        "  Ensemble + TTA:        SKIPPED ← Expected to perform worse\n",
        "\n",
        "🏥 CLINICAL PERFORMANCE (Best Model - Fold 2):\n",
        "  Pneumonia Recall:   91.3%  ← Excellent at catching sick patients\n",
        "  Normal Recall:      75.2%  ← 25% false alarms (needs improvement)\n",
        "  Overall Accuracy:   85.3%  ← Clinically acceptable\n",
        "\n",
        "🚨 ROOT CAUSE IDENTIFIED:\n",
        "  All models overfit validation data by 9-10%\n",
        "  Advanced techniques cannot fix fundamental overfitting\n",
        "  Training data ≠ Real-world test data distribution\n",
        "\n",
        "🎯 DEPLOYMENT RECOMMENDATION:\n",
        "  USE: Single Model (Fold 2) with 85.26% accuracy\n",
        "  AVOID: Ensemble, TTA, and other complex techniques\n",
        "  REASON: Simpler = Better for this medical task\n",
        "\n",
        "💡 NEXT STEPS FOR DAY 6:\n",
        "  1. Address overfitting in model interpretation\n",
        "  2. Analyze error patterns (why 25% false alarms?)\n",
        "  3. Consider data quality improvements\n",
        "  4. Deploy single model with monitoring\n",
        "\"\"\")\n",
        "\n",
        "# Save final Day 5.5 conclusions\n",
        "day5_5_conclusions = {\n",
        "    \"best_method\": \"single_model_fold_2\",\n",
        "    \"best_accuracy\": 0.8526,\n",
        "    \"overfitting_gap\": 0.1023,  # 10.23%\n",
        "    \"clinical_performance\": {\n",
        "        \"pneumonia_recall\": 0.913,\n",
        "        \"normal_recall\": 0.752,\n",
        "        \"false_alarm_rate\": 0.248\n",
        "    },\n",
        "    \"technique_evaluation\": {\n",
        "        \"ensemble\": {\"accuracy\": 0.8365, \"verdict\": \"worse\"},\n",
        "        \"tta\": {\"accuracy\": 0.8494, \"verdict\": \"worse\"},\n",
        "        \"ensemble_tta\": {\"verdict\": \"skipped_expected_worse\"}\n",
        "    },\n",
        "    \"key_finding\": \"advanced_techniques_cannot_fix_overfitting\",\n",
        "    \"deployment_recommendation\": \"use_single_model_simple_approach\"\n",
        "}\n",
        "\n",
        "outputs_dir = Path('/content/notebooks/outputs')\n",
        "with open(outputs_dir / 'day5_5_final_conclusions.json', 'w') as f:\n",
        "    json.dump(day5_5_conclusions, f, indent=2)\n",
        "\n",
        "print(f\"✓ Final conclusions saved to: {outputs_dir / 'day5_5_final_conclusions.json'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DAY 5.5 COMPLETE: REAL TESTING REVEALED CRITICAL INSIGHTS!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N749W9nBcnSs",
        "outputId": "75d15052-25c5-45a1-9a2e-9102bcd008c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DAY 5.5 FINAL SUMMARY & RECOMMENDATIONS\n",
            "================================================================================\n",
            "\n",
            "📊 REAL TEST SET PERFORMANCE (624 images):\n",
            "\n",
            "SINGLE MODELS:\n",
            "  Fold 1: 84.29% (Val: 94.25%) ← OVERFIT: -9.96%\n",
            "  Fold 2: 85.26% (Val: 95.49%) ← OVERFIT: -10.23%  BEST\n",
            "  Fold 3: ~84.00% (Val: 93.77%) ← OVERFIT: ~-9.77%\n",
            "\n",
            "ADVANCED TECHNIQUES:\n",
            "  Ensemble (3 models):   83.65%  ← -1.61% vs best single\n",
            "  TTA (3 variants):      84.94%  ← -0.32% vs best single\n",
            "  Ensemble + TTA:        SKIPPED ← Expected to perform worse\n",
            "\n",
            "🏥 CLINICAL PERFORMANCE (Best Model - Fold 2):\n",
            "  Pneumonia Recall:   91.3%  ← Excellent at catching sick patients\n",
            "  Normal Recall:      75.2%  ← 25% false alarms (needs improvement)\n",
            "  Overall Accuracy:   85.3%  ← Clinically acceptable\n",
            "\n",
            "🚨 ROOT CAUSE IDENTIFIED:\n",
            "  All models overfit validation data by 9-10%\n",
            "  Advanced techniques cannot fix fundamental overfitting\n",
            "  Training data ≠ Real-world test data distribution\n",
            "\n",
            "🎯 DEPLOYMENT RECOMMENDATION:\n",
            "  USE: Single Model (Fold 2) with 85.26% accuracy\n",
            "  AVOID: Ensemble, TTA, and other complex techniques\n",
            "  REASON: Simpler = Better for this medical task\n",
            "\n",
            "💡 NEXT STEPS FOR DAY 6:\n",
            "  1. Address overfitting in model interpretation\n",
            "  2. Analyze error patterns (why 25% false alarms?)\n",
            "  3. Consider data quality improvements\n",
            "  4. Deploy single model with monitoring\n",
            "\n",
            "✓ Final conclusions saved to: /content/notebooks/outputs/day5_5_final_conclusions.json\n",
            "\n",
            "================================================================================\n",
            "DAY 5.5 COMPLETE: REAL TESTING REVEALED CRITICAL INSIGHTS!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}